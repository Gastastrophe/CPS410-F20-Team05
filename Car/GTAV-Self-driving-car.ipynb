{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand Theft Auto V Driving learning with Deep Learning (CNN and YOLO)\n",
    "---\n",
    "Self driving car in Grand Theft Auto V with Deep Learning and Object Detection. Adapted from\n",
    "https://github.com/eritzyg/GTAV-Self-driving-car\n",
    "by Iker Garcia and Eritz Yerga.\n",
    "\n",
    "\n",
    "\n",
    "### Authors: Evan Miller, Allan Bourke, Joshua Gutowski, and Ian Kraft\n",
    "\n",
    "See [this README](https://github.com/eritzyg/GTAV-Self-driving-car/blob/master/Notebook/README.md) for info about the notebook and required libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Index:\n",
    "\n",
    "0. <a href=\"#0.-Object-Detection\">Object Detection</a>\n",
    "1. <a href=\"#1.-Generate-dataset\">Generate dataset</a>\n",
    "    * <a href=\"#Frame-capture-functions\">Frame capture functions</a>\n",
    "    * <a href=\"#Image-preprocessing-functions\">Image preprocess functions</a>\n",
    "    * <a href=\"#Game-control-and-input-reading-functions\">Game control and input reading functions</a>\n",
    "    * <b><a href=\"#Generate-dataset\">Generate dataset</a></b>\n",
    "2. <a href=\"#2.-Dataset-processing-utilities\">Dataset processing utilities</a>\n",
    "3. <a href=\"#3.-Define-the-model\">Define our model</a>\n",
    "4. <a href=\"#4.-Train\">Train</a>\n",
    "5. <a href=\"#5.-Run-our-model-in-the-game\">Run our model in the game</a>\n",
    "\n",
    "<a href=\"\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "First we import the libraries we are going to need to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.19.3 in c:\\users\\emill\\anaconda3\\lib\\site-packages (1.19.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\emill\\anaconda3\\lib\\site-packages (4.4.0.46)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.3)\n",
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/6a/9669836f813b73fe5abf5e9f118ccc9b7fb060f02789d385825b0943f9c8/tensorflow-2.3.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Collecting numpy<1.19.0,>=1.16.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e4/01/7a26148f7de9eb6c27f95b29eba16b7e820827cb9ebaae182d7483e44711/numpy-1.18.5-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.15.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\emill\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\emill\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\emill\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Installing collected packages: numpy, tensorflow\n",
      "  Found existing installation: numpy 1.19.3\n",
      "    Uninstalling numpy-1.19.3:\n",
      "      Successfully uninstalled numpy-1.19.3\n",
      "Successfully installed numpy-1.18.5 tensorflow-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user numpy==1.19.3\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import cv2 \n",
    "import time\n",
    "from sys import stdout\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from grabber import Grabber\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "import glob\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, LSTM, Flatten, Dense, InputLayer, MaxPooling2D, Dropout, Activation, Embedding, GRU, ConvLSTM2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import initializers\n",
    "import h5py\n",
    "import log\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets an array of filepaths to images from a folder\n",
    "\n",
    "def loadImages(path):\n",
    "    # Put files into lists and return them as one list of size 4\n",
    "    image_files = sorted([os.path.join(path, 'train', file)\n",
    "         for file in os.listdir(path + \"/train\") if      file.endswith('.png')])\n",
    " \n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Object Detection\n",
    "By Evan Miller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section utilizes the Yolov3 object detection model with pretrained weights for driving created by Lavanya Shukla on Kaggle. https://www.kaggle.com/lavanyashukla01/yolov3-lyft-dataset/?select=model.h5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Loads the model from the file\n",
    "obj_model = load_model('yolo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Lavanya Shukla on Kaggle.\n",
    "\n",
    "#Custom class for functionality needed to extract bounding boxes from the YOLO model\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    " \n",
    "        return self.score\n",
    " \n",
    "    def _sigmoid(x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    " \n",
    "    def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "        grid_h, grid_w = netout.shape[:2]\n",
    "        nb_box = 3\n",
    "        netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "        nb_class = netout.shape[-1] - 5\n",
    "        boxes = []\n",
    "        netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "        netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "        netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "        netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    " \n",
    "        for i in range(grid_h*grid_w):\n",
    "            row = i / grid_w\n",
    "            col = i % grid_w\n",
    "            for b in range(nb_box):\n",
    "                # 4th element is objectness score\n",
    "                objectness = netout[int(row)][int(col)][b][4]\n",
    "                if(objectness.all() <= obj_thresh): continue\n",
    "                # first 4 elements are x, y, w, and h\n",
    "                x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "                x = (col + x) / grid_w # center position, unit: image width\n",
    "                y = (row + y) / grid_h # center position, unit: image height\n",
    "                w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "                h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "                # last elements are class probabilities\n",
    "                classes = netout[int(row)][col][b][5:]\n",
    "                box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "                boxes.append(box)\n",
    "        return boxes\n",
    " \n",
    "    def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "        new_w, new_h = net_w, net_h\n",
    "        for i in range(len(boxes)):\n",
    "            x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "            y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "            boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "            boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "            boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "            boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "    def _interval_overlap(interval_a, interval_b):\n",
    "        x1, x2 = interval_a\n",
    "        x3, x4 = interval_b\n",
    "        if x3 < x1:\n",
    "            if x4 < x1:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x1\n",
    "        else:\n",
    "            if x2 < x3:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x3\n",
    "\n",
    "    def bbox_iou(box1, box2):\n",
    "        intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "        intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "        intersect = intersect_w * intersect_h\n",
    "        w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "        w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "        union = w1*h1 + w2*h2 - intersect\n",
    "        return float(intersect) / union\n",
    " \n",
    "    def do_nms(boxes, nms_thresh):\n",
    "        if len(boxes) > 0:\n",
    "            nb_class = len(boxes[0].classes)\n",
    "        else:\n",
    "            return\n",
    "        for c in range(nb_class):\n",
    "            sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "            for i in range(len(sorted_indices)):\n",
    "                index_i = sorted_indices[i]\n",
    "                if boxes[index_i].classes[c] == 0: continue\n",
    "                for j in range(i+1, len(sorted_indices)):\n",
    "                    index_j = sorted_indices[j]\n",
    "                    if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                        boxes[index_j].classes[c] = 0\n",
    "\n",
    "    # load and prepare an image\n",
    "    def load_image_pixels(filename, shape):\n",
    "        # load the image to get its shape\n",
    "        image = load_img(filename)\n",
    "        width, height = image.size\n",
    "        # load the image with the required size\n",
    "        image = load_img(filename, target_size=shape)\n",
    "        # convert to numpy array\n",
    "        image = img_to_array(image)\n",
    "        # scale pixel values to [0, 1]\n",
    "        image = image.astype('float32')\n",
    "        image /= 255.0\n",
    "        # add a dimension so that we have one sample\n",
    "        image = expand_dims(image, 0)\n",
    "        return image, width, height\n",
    "    \n",
    "    # get all of the results above a threshold\n",
    "    def get_boxes(boxes, labels, thresh):\n",
    "        v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "        # enumerate all boxes\n",
    "        for box in boxes:\n",
    "            # enumerate all possible labels\n",
    "            for i in range(len(labels)):\n",
    "                # check if the threshold for this label is high enough\n",
    "                if box.classes[i] > thresh:\n",
    "                    v_boxes.append(box)\n",
    "                    v_labels.append(labels[i])\n",
    "                    v_scores.append(box.classes[i]*100)\n",
    "                    # don't break, many labels may trigger for one box\n",
    "        return v_boxes, v_labels, v_scores\n",
    " \n",
    "    # draw all results\n",
    "    def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "        # load the image\n",
    "        data = pyplot.imread(filename)\n",
    "        # plot the image\n",
    "        pyplot.imshow(data)\n",
    "        # get the context for drawing boxes\n",
    "        ax = pyplot.gca()\n",
    "        # plot each box\n",
    "        for i in range(len(v_boxes)):\n",
    "            box = v_boxes[i]\n",
    "            # get coordinates\n",
    "            y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "            # calculate width and height of the box\n",
    "            width, height = x2 - x1, y2 - y1\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "            # draw text and score in top left corner\n",
    "            label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "            pyplot.text(x1, y1, label, color='white')\n",
    "        # show the plot\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes a normalized rgb image file and returns a list of two image arrays. The first has the objects and the second has everything else.\n",
    "#Adapted from Lavanya Shukla on Kaggle. Written by Evan Miller.\n",
    "\n",
    "def get_sub_images(imagepath):\n",
    "    #get image size and model paramaters\n",
    "    WIDTH, HEIGHT = 416,416\n",
    "    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "    class_threshold = 0.3\n",
    "    \n",
    "    #load original image\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    IMAGE = img_to_array(image)\n",
    "    \n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, target_size=(WIDTH,HEIGHT))\n",
    "    \n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    \n",
    "    #normalize image and add a dimension\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    image = expand_dims(image, 0)\n",
    "    \n",
    "    yhat = obj_model.predict(image)\n",
    "    \n",
    "    # Create boxes\n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "        # decode the output of the network\n",
    "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, HEIGHT, WIDTH)\n",
    "    \n",
    "    # correct the sizes of the bounding boxes for the shape of the image\n",
    "    correct_yolo_boxes(boxes, height, width, HEIGHT, WIDTH)\n",
    "    \n",
    "    # suppress non-maximal boxes\n",
    "    do_nms(boxes, 0.5)\n",
    "    \n",
    "    # get the details of the detected objects\n",
    "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "    \n",
    "    objects = np.zeros_like(IMAGE)\n",
    "    background = IMAGE[:]\n",
    "    \n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # Loop over area of each box\n",
    "        for i in range(x1,x2):\n",
    "            for j in range(y1,y2):\n",
    "                # Data is channels last, so we copy and erase whole channels here\n",
    "                # objects contains all values within the box\n",
    "                objects[j][i] = IMAGE[j][i][:]\n",
    "                # background gets this coordinate erased and is left with the remainder of the image\n",
    "                background[j][i] = np.zeros_like(IMAGE[j][i])\n",
    "    \n",
    "    return [objects, background]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate the dataset for training the model later on, it is important that we set the game on the first person view and take into account certain conditions for the dataset. Check the \"Generation of the dataset\" section in the [documentation](https://github.com/eritzyg/GTAV-Self-driving-car#documentation) for more information on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame capture functions\n",
    "These functions capture the game's frames in 1600x900 Windowed mode.\n",
    "\n",
    "Screen record is the method to get one frame and img_thread is the thread we will later use to constantly capture the game's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "global grb\n",
    "grb = Grabber(bbox=(1,26,1601,926))\n",
    "def screen_record(method = 'grabber'):\n",
    "    if method == 'ImageGrab':\n",
    "        printscreen =  ImageGrab.grab(bbox=(1,26,1601,926))\n",
    "        generalIMG = np.array(printscreen)\n",
    "    \n",
    "    elif method == 'grabber':\n",
    "        global grb\n",
    "        printscreen = None\n",
    "        printscreen = grb.grab(printscreen)\n",
    "        generalIMG = np.array(printscreen)\n",
    "    \n",
    "    return generalIMG          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "global front_buffer\n",
    "global back_buffer\n",
    "front_buffer = np.zeros((1600, 900), dtype=np.int8)\n",
    "back_buffer = np.zeros((1600, 900), dtype=np.int8)\n",
    "\n",
    "global fps\n",
    "fps = 0\n",
    "\n",
    "def img_thread():\n",
    "    global front_buffer\n",
    "    global back_buffer\n",
    "    global fps\n",
    "    \n",
    "    last_time = time.time()\n",
    "    while True:\n",
    "        front_buffer = screen_record()\n",
    "        # Swap buffers\n",
    "        front_buffer, back_buffer = back_buffer, front_buffer\n",
    "        fps = int(1.0/(time.time()-last_time))\n",
    "        last_time = time.time()\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a function that will apply the preprocessing we want to the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code inspired by https://towardsdatascience.com/image-pre-processing-c1aec0be3edf\n",
    "# Ideas written by Prince Canuma\n",
    "\n",
    "#adds Gaussian blur to an image\n",
    "\n",
    "def blur(res_img):\n",
    "\n",
    "    no_noise = []\n",
    "    for i in range(len(res_img)):\n",
    "        blur = cv2.GaussianBlur(res_img[i], (5, 5), 0)\n",
    "        no_noise.append(blur)\n",
    "\n",
    "    return no_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    proccessed_image = cv2.resize(image,(480,270))\n",
    "    proccessed_image = blur(proccessed_image)\n",
    "    \n",
    "    return proccessed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game control and input reading functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions will read the inputs and generate a array for later use when generating the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game_control import PressKey, ReleaseKey\n",
    "from getkeys import key_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_to_output(keys):\n",
    "    '''\n",
    "    Convert keys to a ...multi-hot... array\n",
    "\n",
    "    [A,W,D] boolean values.\n",
    "    '''\n",
    "    output = [0,0,0,0]\n",
    "    \n",
    "    if 'A' in keys:\n",
    "        output[0] = 1\n",
    "    if 'D' in keys:\n",
    "        output[1] = 1\n",
    "    if 'W' in keys:\n",
    "        output[2] = 1\n",
    "    if 'S' in keys:\n",
    "        output[3] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sequencer thread will capture the sequences of 5 frames with a separation of 1/capturerate ms each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "global seq\n",
    "global num\n",
    "num = 0\n",
    "seq = []\n",
    "\n",
    "global key_out\n",
    "key_out = [0, 0, 0, 0]\n",
    "\n",
    "def image_sequencer_thread():\n",
    "    global back_buffer\n",
    "    global seq\n",
    "    global key_out\n",
    "    global num\n",
    "    \n",
    "    # Frames per second capture rate\n",
    "    capturerate = 10.0\n",
    "    while True:\n",
    "        last_time = time.time()\n",
    "        if len(seq) == 5:\n",
    "            del seq[0]\n",
    "\n",
    "        seq.append(preprocess_image(np.copy(back_buffer)))\n",
    "        num = num + 1\n",
    "        keys = key_check()\n",
    "        key_out = keys_to_output(keys)\n",
    "        waittime = (1.0/capturerate)-(time.time()-last_time)\n",
    "        if waittime>0.0:\n",
    "            time.sleep(waittime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be useful to check which class corresponds the input we captured to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_keys(key):\n",
    "        if np.array_equal(key , [0,0,0,0]):\n",
    "            return 0\n",
    "        elif np.array_equal(key , [1,0,0,0]):\n",
    "            return 1\n",
    "        elif np.array_equal(key , [0,1,0,0]):\n",
    "            return 2\n",
    "        elif np.array_equal(key , [0,0,1,0]):\n",
    "            return 3\n",
    "        elif np.array_equal(key , [0,0,0,1]):\n",
    "            return 4\n",
    "        elif np.array_equal(key , [1,0,1,0]):\n",
    "            return 5\n",
    "        elif np.array_equal(key , [1,0,0,1]):\n",
    "            return 6\n",
    "        elif np.array_equal(key , [0,1,1,0]):\n",
    "            return 7\n",
    "        elif np.array_equal(key , [0,1,0,1]):\n",
    "            return 8\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that the data saving threads will run to save the dataset to compressed files (change the path if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data,number):\n",
    "    file_name = 'F:\\\\GTAV_AI\\\\training_data'+str(number)+'.npz'\n",
    "    np.savez_compressed(file_name,data)\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run this function to generate the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    global fps\n",
    "    global front_buffer\n",
    "    global back_buffer\n",
    "    global seq\n",
    "    global key_out\n",
    "    global num\n",
    "    training_data = []\n",
    "    threads = list()\n",
    "    th_img = threading.Thread(target=img_thread)\n",
    "    th_seq = threading.Thread(target=image_sequencer_thread)\n",
    "    threads.append(th_img)\n",
    "    threads.append(th_seq)\n",
    "    th_img.start()\n",
    "    time.sleep(1)\n",
    "    th_seq.start()\n",
    "    l = 0\n",
    "    fn = 0\n",
    "    time.sleep(4)\n",
    "    last_num = 0\n",
    "    \n",
    "    number_of_keys = [0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    while True:\n",
    "        img_seq = seq.copy()\n",
    "        output = key_out.copy()\n",
    "        \n",
    "        while len(img_seq) != 5 or last_num==num:\n",
    "            del img_seq, output\n",
    "            img_seq = seq.copy()\n",
    "            output = key_out.copy()\n",
    "        last_num = num\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        stdout.write('Recording at {} FPS \\n'.format(fps))\n",
    "        stdout.write('Images in sequence {} \\n'.format(len(img_seq)))\n",
    "        stdout.write('Training data len {} secuences \\n'.format(l))\n",
    "        stdout.write('Number of archives {}\\n'.format(fn))\n",
    "        stdout.write('Keys pressed: ' + str(output) + ' \\n')\n",
    "        stdout.write('Keys samples in this file: ' + 'none:' + str(number_of_keys[0]) + ' A:' + str(number_of_keys[1])+ ' D:' + str(number_of_keys[2]) + ' W:' + str(number_of_keys[3])+ ' S:' + str(number_of_keys[4]) + ' AW:'  + str(number_of_keys[5]) + ' AS:' + str(number_of_keys[6]) + ' WD:' + str(number_of_keys[7]) + ' SD:' + str(number_of_keys[8]) + ' \\n')\n",
    "        stdout.flush()\n",
    "        \n",
    "        key  = counter_keys(output)\n",
    "        \n",
    "        if key != -1:\n",
    "            larg = nlargest(9,number_of_keys)\n",
    "            prop = (9. - float(larg.index(number_of_keys[key])))/10\n",
    "            if(number_of_keys[key]  > np.mean(number_of_keys) * 1.25):\n",
    "                prop = prop + 0.05\n",
    "            if (np.random.rand() > prop):\n",
    "                number_of_keys[key] += 1\n",
    "                l = l+1\n",
    "                training_data.append([img_seq[0],img_seq[1],img_seq[2],img_seq[3],img_seq[4], output])\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        if len(training_data) % 500 == 0:\n",
    "            print(len(training_data))\n",
    "            threading.Thread(target=save_data, args=(training_data.copy(), fn,)).start()\n",
    "            fn = fn + 1\n",
    "            del training_data\n",
    "            training_data = []\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the capture and generation of the dataset, remember that the game's window must be in 1600x900 resolution and located in the top left part of the screen ((0,0) coordinates).\n",
    "\n",
    "Once you captured all the data you need you can interrupt the kernel to stop the run function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording at 12 FPS \n",
      "Images in sequence 5 \n",
      "Training data len 2 secuences \n",
      "Number of archives 8\n",
      "Keys pressed: [0, 0, 0, 0] \n",
      "Keys samples in this file: none:2 A:0 D:0 W:0 S:0 AW:0 AS:0 WD:0 SD:0 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-44169bf108b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-b11b88146033>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mimg_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mimg_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mlast_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time.sleep(5)\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset processing utilities\n",
    "Some of these functions are not used, but we include them for debug purposes. Others are used later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot some data to see if it captured correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImgs = False\n",
    "if plotImgs:\n",
    "    with np.load('F:\\\\GTAV_AI\\\\filename.npz') as data:\n",
    "        training_data = data['arr_0']\n",
    "    i= 502\n",
    "    plt.imshow(cv2.cvtColor(training_data[i][0], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    plt.imshow(cv2.cvtColor(training_data[i][1], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    plt.imshow(cv2.cvtColor(training_data[i][2], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    plt.imshow(cv2.cvtColor(training_data[i][3], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    plt.imshow(cv2.cvtColor(training_data[i][4], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to count the number of instances per class in a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_instances_per_class(data):\n",
    "    \n",
    "    nonekey = []\n",
    "    A = []\n",
    "    D = []\n",
    "    W = []\n",
    "    S = []\n",
    "    \n",
    "    AD = []\n",
    "    AW = []\n",
    "    AS = []\n",
    "    DW =[]\n",
    "    DS = []\n",
    "    WS =[]\n",
    "    \n",
    "    ADW = []\n",
    "    AWS =[]\n",
    "    ADS = []\n",
    "    DWS = []\n",
    "    \n",
    "    ASWS = []\n",
    "    \n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    for d in data:\n",
    "        if np.array_equal(d[5] , [0,0,0,0]):\n",
    "            nonekey.append(d)\n",
    "        elif np.array_equal(d[5] , [1,0,0,0]):\n",
    "            A.append(d)\n",
    "        elif np.array_equal(d[5] , [0,1,0,0]):\n",
    "            D.append(d)\n",
    "        elif np.array_equal(d[5] , [0,0,1,0]):\n",
    "            W.append(d)\n",
    "        elif np.array_equal(d[5] , [0,0,0,1]):\n",
    "            S.append(d)\n",
    "        elif np.array_equal(d[5] , [1,1,0,0]):\n",
    "            AD.append(d)\n",
    "        elif np.array_equal(d[5] , [1,0,1,0]):\n",
    "            AW.append(d)\n",
    "        elif np.array_equal(d[5] , [1,0,0,1]):\n",
    "            AS.append(d)\n",
    "        elif np.array_equal(d[5] , [0,1,1,0]):\n",
    "            DW.append(d)\n",
    "        elif np.array_equal(d[5] , [0,1,0,1]):\n",
    "            DS.append(d)\n",
    "        elif np.array_equal(d[5] , [0,0,1,1]):\n",
    "            WS.append(d)\n",
    "        elif np.array_equal(d[5] , [1,1,1,0]):\n",
    "            ADW.append(d)\n",
    "        elif np.array_equal(d[5] , [1,1,0,1]):\n",
    "            AWS.append(d)\n",
    "        elif np.array_equal(d[5] , [1,1,0,1]):\n",
    "            ADS.append(d)\n",
    "        elif np.array_equal(d[5] , [0,1,1,1]):\n",
    "            DWS.append(d)\n",
    "        elif np.array_equal(d[5] , [1,1,1,1]):\n",
    "            ASWS.append(d)\n",
    "    return [nonekey,A,D,W,S,AW,AS,DW,DS]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will balance the number of instances of the classes in a set by deleting extra instances after shuffling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(data_in_clases):\n",
    "    balanced_data = []\n",
    "    data_in_clases.sort(key=len)\n",
    "    max_len = len(data_in_clases[0])\n",
    "        \n",
    "    for data in data_in_clases:\n",
    "        if len(data) > max_len:\n",
    "            data=data[:max_len]\n",
    "        for d in data:\n",
    "            balanced_data.append(d)\n",
    "        \n",
    "    np.random.shuffle(balanced_data)\n",
    "    \n",
    "    return balanced_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debug purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "if debug:\n",
    "    with np.load('F:\\\\GTAV_AI\\\\training_data'+str(20)+'.npz') as data:\n",
    "         training_data = data['arr_0']\n",
    "    number = number_instances_per_class(training_data)\n",
    "    print('none: ' + str(len(number[0])))\n",
    "    print('A: ' + str(len(number[1])))\n",
    "    print('D ' + str(len(number[2])))\n",
    "    print('W ' + str(len(number[3])))\n",
    "    print('S ' + str(len(number[4])))\n",
    "    print('AW ' + str(len(number[5])))\n",
    "    print('AS ' + str(len(number[6])))\n",
    "    print('DW ' + str(len(number[7])))\n",
    "    print('DS ' + str(len(number[8])))\n",
    "\n",
    "    balanced_data = balance_data(number)\n",
    "    number = number_instances_per_class(balanced_data)\n",
    "    print('none: ' + str(len(number[0])))\n",
    "    print('A: ' + str(len(number[1])))\n",
    "    print('D ' + str(len(number[2])))\n",
    "    print('W ' + str(len(number[3])))\n",
    "    print('S ' + str(len(number[4])))\n",
    "    print('AW ' + str(len(number[5])))\n",
    "    print('AS ' + str(len(number[6])))\n",
    "    print('DW ' + str(len(number[7])))\n",
    "    print('DS ' + str(len(number[8])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the model to use in our training, please select the model you want to use in the cell bellow (the models are described in the \"Definition of the DNN\" of the [documentation](https://github.com/eritzyg/GTAV-Self-driving-car#documentation)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model to use:\n",
    "# 'CNN+MPL' : Convolutional neural network with multi layer perceptron.\n",
    "# 'CNN+RNN' : Convolutional neural network with recurrent neural network.\n",
    "selected_model = 'CNN+RNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we define the corresponding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 267, 477, 32)\n",
      "(None, 5, 264, 474, 32)\n",
      "(None, 5, 52, 94, 32)\n",
      "(None, 5, 50, 92, 16)\n",
      "(None, 5, 10, 18, 16)\n",
      "(None, 5, 2880)\n",
      "(None, 256)\n",
      "(None, 100)\n",
      "(None, 80)\n",
      "(None, 40)\n",
      "(None, 9)\n"
     ]
    }
   ],
   "source": [
    "if selected_model == 'CNN+RNN':\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(InputLayer(input_shape=(5, 270, 480, 3)))\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(32, (4,4), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(32, (4,4), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(16, (3,3), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(GRU(256, kernel_initializer=initializers.RandomNormal(stddev=0.001))) #128\n",
    "    model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(100))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(80))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(40))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(9, activation='sigmoid'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    opt = optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model == 'CNN+MLP':\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(InputLayer(input_shape=(5, 270, 480, 3)))\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(16, (4,8), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(16, (4,4), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(12, (3,3), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(300))\n",
    "    print(model.output_shape)\n",
    "    model.add(Dense(100))\n",
    "    print(model.output_shape)\n",
    "    print(model.output_shape)\n",
    "    model.add(Dense(9, activation='sigmoid'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    opt = optimizers.rmsprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define some functions to reshape the data according to the input of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_custom_X(data, verbose = 1):\n",
    "    reshaped = np.zeros((data.shape[0], 5, 270, 480, 3), dtype=np.float32)\n",
    "    for i in range(0, data.shape[0]):\n",
    "        for j in range(0, 5):\n",
    "            if (verbose == 1):\n",
    "                clear_output(wait=True)\n",
    "                stdout.write('Reshaped image: ' + str(i))\n",
    "                stdout.flush()\n",
    "            reshaped[i][j] = data[i][j]/255.\n",
    "            \n",
    "    return reshaped\n",
    "\n",
    "def reshape_custom_y(data):\n",
    "    reshaped = np.zeros((data.shape[0], 9), dtype=np.float32)\n",
    "    for i in range(0, data.shape[0]):\n",
    "            if np.array_equal(data[i][0] , [0,0,0,0]):\n",
    "                reshaped[i][0] = 1.\n",
    "            elif np.array_equal(data[i][0] , [1,0,0,0]):\n",
    "                reshaped[i][1] = 1.\n",
    "            elif np.array_equal(data[i][0] , [0,1,0,0]):\n",
    "                reshaped[i][2] = 1.\n",
    "            elif np.array_equal(data[i][0] , [0,0,1,0]):\n",
    "                reshaped[i][3] = 1.\n",
    "            elif np.array_equal(data[i][0] , [0,0,0,1]):\n",
    "                reshaped[i][4] = 1.\n",
    "            elif np.array_equal(data[i][0] , [1,0,1,0]):\n",
    "                reshaped[i][5] = 1.\n",
    "            elif np.array_equal(data[i][0] , [1,0,0,1]):\n",
    "                reshaped[i][6] = 1.\n",
    "            elif np.array_equal(data[i][0] , [0,1,1,0]):\n",
    "                reshaped[i][7] = 1.\n",
    "            elif np.array_equal(data[i][0] , [0,1,0,1]):\n",
    "                reshaped[i][8] = 1.\n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions will help for picking the number of batches and the start and end indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_batches(length, BATCH_SIZE):\n",
    "    if (int(length/BATCH_SIZE)*BATCH_SIZE == length):\n",
    "        return int(length/BATCH_SIZE)\n",
    "    else:\n",
    "        return int(length/BATCH_SIZE)+1\n",
    "\n",
    "def get_start_end(iteration, BATCH_SIZE, max_length):\n",
    "    start = iteration*BATCH_SIZE\n",
    "    if (start > max_length):\n",
    "        print(\"ERROR: Check iterations made! Must be wrong\")\n",
    "        return -1, -1\n",
    "    end = (iteration+1)*BATCH_SIZE\n",
    "    if (end > max_length):\n",
    "        end = max_length\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we run the training process, the accuracy can be seen after each epoch (all the inputs will be saved to a \"log.txt\" file, so don't worry if you miss out some output). Also remember to change the path to the same path where you saved the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.openlog()\n",
    "\n",
    "# Define the sizes and epoches\n",
    "BATCH_SIZE = 10\n",
    "TEST_BATCH_SIZE = 10\n",
    "n_epochs = 6\n",
    "\n",
    "# This path will be the path used to load the dataset files!\n",
    "files = glob.glob(\"F:\\\\GTAV_AI\\\\merged\\\\*.npz\")\n",
    "\n",
    "\n",
    "actual_file = 0\n",
    "acc_for_files = []\n",
    "for fil in files:\n",
    "    actual_file = actual_file + 1\n",
    "    log.output(\"\\n Loading input: \"+fil)\n",
    "    with np.load(fil) as data:\n",
    "         training_data = data['arr_0']\n",
    "\n",
    "    #print(\"\\n Balancing data...\")\n",
    "    #number = number_instances_per_class(training_data)\n",
    "    #training_data = np.array(balance_data(number))\n",
    "\n",
    "    log.output(\"\\n Reshaping data...\")\n",
    "    np.random.shuffle(training_data)\n",
    "    train = training_data[0:int(len(training_data)*0.90)]\n",
    "    test = training_data[int(len(training_data)*0.90):len(training_data)]\n",
    "    del training_data\n",
    "    X_train = reshape_custom_X(train[:, 0:5])\n",
    "    y_train = reshape_custom_y(train[:, 5:6])\n",
    "    X_test = reshape_custom_X(test[:, 0:5])\n",
    "    y_test= reshape_custom_y(test[:, 5:6])\n",
    "    del train, test\n",
    "    log.output(\"\\n Training...\")\n",
    "    data_length = len(X_train)\n",
    "    n_batch = get_num_batches(data_length, BATCH_SIZE)\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_batch):\n",
    "            start, end = get_start_end(iteration, BATCH_SIZE, data_length)\n",
    "            model.fit(x=X_train[start:end], y=y_train[start:end], epochs=1, verbose=0)\n",
    "            clear_output(wait=True)\n",
    "            log.output('\\n => File : ' + str(actual_file) + ' of ' + str(len(files)))\n",
    "            log.output('\\n ==> EPOCH : ' + str(epoch+1) + ' of ' + str(n_epochs))\n",
    "            log.output('\\n ===> Iteration: ' + str(iteration+1) + ' of ' + str(n_batch))\n",
    "            #score = model.evaluate(X_train[start:end], y_train[start:end], verbose=0)\n",
    "            #log.output(\"\\n Train batch accuracy: %.2f%%\" % (score[1]*100))\n",
    "            stdout.flush()\n",
    "        prec = np.zeros((9))\n",
    "        for i in range(len(y_test)):\n",
    "            p = model.predict_classes(X_test[i:i+1])\n",
    "            prec[p] = prec[p] + 1\n",
    "        log.output(\"\\n ==> Predictions:\"+str(prec))\n",
    "        stdout.flush()   \n",
    "    total_acc = 0.0\n",
    "    num = 0\n",
    "    data_length = len(X_test)\n",
    "    n_batch = get_num_batches(data_length, TEST_BATCH_SIZE)\n",
    "    for iteration in range(n_batch):\n",
    "        start, end = get_start_end(iteration, TEST_BATCH_SIZE, data_length)\n",
    "        score = model.evaluate(X_test[start:end], y_test[start:end], verbose=0)\n",
    "        log.output(\"\\n => Batch %s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "        total_acc = total_acc + score[1]\n",
    "        num = num + 1\n",
    "    total_acc = total_acc/float(num)\n",
    "    log.output(\"\\n ==> Total acc for file %s: %.2f%%\" % (fil, total_acc*100))\n",
    "    acc_for_files.append(total_acc*100)\n",
    "\n",
    "\n",
    "    prec = np.zeros((9))\n",
    "    for i in range(len(y_test)):\n",
    "        p = model.predict_classes(X_test[i:i+1])\n",
    "        prec[p] = prec[p] + 1\n",
    "    log.output(\"\\n ==> Predictions:\"+str(prec))\n",
    "    time.sleep(5)\n",
    "\n",
    "for acc in range(len(acc_for_files)):\n",
    "    log.output(\"\\n ==> Total acc after file %d: %.2f%%\" % (acc, acc_for_files[acc]))\n",
    "    \n",
    "    \n",
    "log.closelog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the learned network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\emill\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\emill\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a directory: E:; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-694dff4ae5bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:\\\\GTAV_AI\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mselected_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \"\"\"\n\u001b[0;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1979\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m   def save_weights(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[1;32m--> 134\u001b[1;33m                           signatures, options)\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# we use the default replica context here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m       \u001b[0msave_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m    979\u001b[0m   \u001b[1;31m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m   \u001b[1;31m# the SavedModel proto itself.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m   \u001b[0mutils_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m   ckpt_options = checkpoint_options.CheckpointOptions(\n\u001b[0;32m    983\u001b[0m       experimental_io_device=options.experimental_io_device)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\utils_impl.py\u001b[0m in \u001b[0;36mget_or_create_variables_dir\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    212\u001b[0m   \u001b[0mvariables_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mvariables_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m   \"\"\"\n\u001b[1;32m--> 465\u001b[1;33m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m   \"\"\"\n\u001b[1;32m--> 480\u001b[1;33m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a directory: E:; No such file or directory"
     ]
    }
   ],
   "source": [
    "import h5py as h5py\n",
    "model.save('F:\\\\GTAV_AI\\\\'+selected_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run our model in the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to test our model in the game, we will reduce the amount of VRAM tensorflow can use so that the game has some VRAM in spare. We will also import the library needed to send inputs to the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the game have some VRAM (needed or the game will crash)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "# For controlling the game\n",
    "from inputsHandler import select_key\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_press(key):\n",
    "    if key == 1:\n",
    "        return'A'\n",
    "    if key == 2:\n",
    "        return'D'\n",
    "    if key == 3:\n",
    "        return'W'\n",
    "    if key == 4:\n",
    "        return'S'\n",
    "    if key == 5:\n",
    "        return'AW'\n",
    "    if key == 6:\n",
    "        return'AS'\n",
    "    if key == 7:\n",
    "        return'DW'\n",
    "    if key == 8:\n",
    "        return'DS'\n",
    "    return 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fuction calculates the Mean Squared Error between 2 images. Is used to detect if the car is stuck somewhere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the run function for our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Configurations\n",
    "show_current_control = False #It will show a windows with a message indicating if the car is currently be controlled by\n",
    "                            #Network  or by a Human\n",
    "    \n",
    "show_whatAIsees = False #It will show the 5 images that the netowrk uses the predict the output \n",
    "\n",
    "enable_evasion = False #If the program detects that the car is not moving (for example because it is stuck facing a wall and\n",
    "                        #the network is not able to return to the road) It will make the car move backwards for a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_IA():\n",
    "    global fps\n",
    "    global front_buffer\n",
    "    global back_buffer\n",
    "    global seq\n",
    "    global key_out\n",
    "    global num\n",
    "    \n",
    "    model = load_model('F:\\\\GTAV_AI\\\\'+selected_model)\n",
    "    \n",
    "    training_data = []\n",
    "    threads = list()\n",
    "    th_img = threading.Thread(target=img_thread)\n",
    "    th_seq = threading.Thread(target=image_sequencer_thread)\n",
    "    threads.append(th_img)\n",
    "    threads.append(th_seq)\n",
    "    th_img.start()\n",
    "    time.sleep(1)\n",
    "    th_seq.start()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    last_num = 0\n",
    "    \n",
    "    last_time = time.time()\n",
    "    \n",
    "    if show_current_control:\n",
    "        root = Tk()\n",
    "        var = StringVar()\n",
    "        var.set('IA CONDUCIENDO')\n",
    "        l = Label(root, textvariable = var, fg='green', font=(\"Courier\", 44))\n",
    "        l.pack()\n",
    "\n",
    "    \n",
    "    while True:\n",
    "       \n",
    "        img_seq = seq.copy()\n",
    "        while len(img_seq) != 5 or last_num==num:\n",
    "            del img_seq\n",
    "            img_seq = seq.copy()\n",
    "        last_num = num\n",
    "        array=[]\n",
    "        array.append([img_seq[0],img_seq[1],img_seq[2],img_seq[3],img_seq[4]])\n",
    "        NNinput = np.array(array)\n",
    "        \n",
    "        x = reshape_custom_X(NNinput[:,0:5],0)\n",
    "        p = model.predict_classes(x)\n",
    "        \n",
    "        if not 'J' in key_check():\n",
    "            select_key(p[0])\n",
    "            if show_current_control:\n",
    "                var.set('IA CONDUCIENDO')\n",
    "                l.config(fg='green')\n",
    "                root.update()\n",
    "        else:\n",
    "            if show_current_control:\n",
    "                var.set('CONTROL MANUAL')\n",
    "                l.config(fg='red')\n",
    "                root.update()\n",
    "\n",
    "        #This is used to detect if the car is stuck somewhere (for example facing a wall) and the network does not know what to do. It will move the car\n",
    "        #backward for a second.\n",
    "        \n",
    "        if enable_evasion:\n",
    "            score = mse(img_seq[0],img_seq[4])\n",
    "            if score < 1000:\n",
    "                if show_current_control:\n",
    "                    var.set('MANIOBRA DE EVASIÓN')\n",
    "                    l.config(fg='blue')\n",
    "                    root.update()\n",
    "                select_key(4)\n",
    "                time.sleep(1)\n",
    "                if np.random.rand()>0.5:\n",
    "                    select_key(6)\n",
    "                else:\n",
    "                    select_key(8)\n",
    "                time.sleep(0.2)\n",
    "                if show_current_control:\n",
    "                    var.set('IA CONDUCIENDO')\n",
    "                    l.config(fg='green')\n",
    "                    root.update()\n",
    "\n",
    "        time_act = time.time()\n",
    "        clear_output(wait=True)\n",
    "        stdout.write('Recording at {} FPS \\n'.format(fps))\n",
    "        stdout.write('Images in sequence {} \\n'.format(len(img_seq)))\n",
    "        stdout.write('Keys pressed: ' + key_press(p[0]) + '\\n')\n",
    "        stdout.write('Actions per second: ' + str(1/(time_act-last_time)) + '\\n')\n",
    "        if enable_evasion:\n",
    "            stdout.write('Diference from img 1 to img 5: ' + str(score))\n",
    "        stdout.flush()\n",
    "        last_time = time.time()\n",
    "        \n",
    "        if show_whatAIsees:\n",
    "            cv2.imshow('window1',np.array(img_seq[0])) \n",
    "            cv2.imshow('window2',np.array(img_seq[1]))\n",
    "            cv2.imshow('window3',np.array(img_seq[2]))\n",
    "            cv2.imshow('window4',np.array(img_seq[3]))\n",
    "            cv2.imshow('window5',np.array(img_seq[4]))\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we run the network in the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: E:\\GTAV_AI\\CNN+RNN/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f8d34d75e371>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_IA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-b2c4af4854d0>\u001b[0m in \u001b[0;36mrun_IA\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:\\\\GTAV_AI\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mselected_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m       \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    111\u001b[0m                   (export_dir,\n\u001b[0;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: E:\\GTAV_AI\\CNN+RNN/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "run_IA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
