{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand Theft Auto V Driving learning with Deep Learning (CNN and YOLO)\n",
    "---\n",
    "Self driving car in Grand Theft Auto V with Deep Learning and Object Detection. Adapted from\n",
    "https://github.com/eritzyg/GTAV-Self-driving-car\n",
    "by Iker Garcia and Eritz Yerga.\n",
    "\n",
    "\n",
    "\n",
    "### Authors: Evan Miller, Allan Bourke\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Index:\n",
    "\n",
    "0. <a href=\"#0.-Object-Detection\">Object Detection</a>\n",
    "1. <a href=\"#1.-Generate-dataset\">Generate dataset</a>\n",
    "    * <a href=\"#Frame-capture-functions\">Frame capture functions</a>\n",
    "    * <a href=\"#Image-preprocessing-functions\">Image preprocess functions</a>\n",
    "    * <a href=\"#Game-control-and-input-reading-functions\">Game control and input reading functions</a>\n",
    "    * <b><a href=\"#Generate-dataset\">Generate dataset</a></b>\n",
    "2. <a href=\"#2.-Dataset-processing-utilities\">Dataset processing utilities</a>\n",
    "3. <a href=\"#3.-Define-the-model\">Define our model</a>\n",
    "4. <a href=\"#4.-Train\">Train</a>\n",
    "5. <a href=\"#5.-Run-our-model-in-the-game\">Run our model in the game</a>\n",
    "\n",
    "<a href=\"\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "First we import the libraries we are going to need to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import cv2 \n",
    "import time\n",
    "from sys import stdout\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from grabber import Grabber\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "import glob\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import TimeDistributed, LSTM, Flatten, Dense, InputLayer, MaxPooling2D, Dropout, Activation, Embedding, GRU, ConvLSTM2D, concatenate\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import initializers\n",
    "import h5py\n",
    "import log\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Object Detection\n",
    "By Evan Miller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section utilizes the Yolov3 object detection model with pretrained weights for driving created by Lavanya Shukla on Kaggle. https://www.kaggle.com/lavanyashukla01/yolov3-lyft-dataset/?select=model.h5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the model from the file\n",
    "obj_model = load_model('yolo.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Lavanya Shukla on Kaggle.\n",
    "\n",
    "#Custom class for functionality needed to extract bounding boxes from the YOLO model\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    " \n",
    "        return self.score\n",
    " \n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def _softmax(x, axis=-1):\n",
    "    x = x - np.amax(x, axis, keepdims=True)\n",
    "    e_x = np.exp(x)\n",
    "    \n",
    "    return e_x / e_x.sum(axis, keepdims=True)\n",
    " \n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4]   = _sigmoid(netout[..., 4])\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i // grid_w\n",
    "        col = i % grid_w\n",
    "        \n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[row, col, b, 4]\n",
    "            \n",
    "            if(objectness <= obj_thresh): continue\n",
    "            \n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[row,col,b,:4]\n",
    "\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n",
    "            \n",
    "            # last elements are class probabilities\n",
    "            classes = netout[row,col,b,5:]\n",
    "            \n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "#TODO: Minimize implementation for images that don't need resizing\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
    "        new_w = net_w\n",
    "        new_h = (image_h*net_w)/image_w\n",
    "    else:\n",
    "        new_h = net_w\n",
    "        new_w = (image_w*net_h)/image_h\n",
    "        \n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        \n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "        \n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    return float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "        \n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    return image, width, height\n",
    "\n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "                # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores\n",
    "\n",
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "    # load the image\n",
    "    data = pyplot.imread(filename)\n",
    "    # plot the image\n",
    "    pyplot.imshow(data)\n",
    "    # get the context for drawing boxes\n",
    "    ax = pyplot.gca()\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # create the shape\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "        pyplot.text(x1, y1, label, color='white')\n",
    "    # show the plot\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes a normalized rgb image and returns a tuple of two image arrays. The first has the objects and the second has everything else.\n",
    "#Adapted from Lavanya Shukla on Kaggle. Written by Evan Miller.\n",
    "\n",
    "def get_sub_images(IMAGE):\n",
    "    # declare labels for the model\n",
    "    labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\"]\n",
    "    \n",
    "    # get image size and model paramaters\n",
    "    WIDTH, HEIGHT = 416,416\n",
    "    \n",
    "    # Set starting anchor positions and threshold for detecting an object\n",
    "    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "    class_threshold = 0.3\n",
    "    \n",
    "    # normalize image and add a dimension\n",
    "    IMAGE = IMAGE.astype('float32')\n",
    "    IMAGE /= 255.0\n",
    "    inpt = np.expand_dims(IMAGE, 0)\n",
    "    \n",
    "    # Use YOLO to find bounding boxes\n",
    "    yhat = obj_model.predict(inpt)\n",
    "    \n",
    "    # Create boxes\n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "        # decode the output of the network\n",
    "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, HEIGHT, WIDTH)\n",
    "    \n",
    "    # correct the sizes of the bounding boxes for the shape of the image\n",
    "    correct_yolo_boxes(boxes, HEIGHT, WIDTH, HEIGHT, WIDTH)\n",
    "    \n",
    "    # suppress non-maximal boxes\n",
    "    do_nms(boxes, 0.5)\n",
    "    \n",
    "    # get the details of the detected objects\n",
    "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "    \n",
    "    # values are True where there is an object\n",
    "    mask_object = np.zeros((HEIGHT,WIDTH,3), dtype=bool)\n",
    "    \n",
    "    for x in range(len(v_boxes)):\n",
    "        box = v_boxes[x]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # Loop over area of each box\n",
    "        for i in range(x1,x2):\n",
    "            if i >= 416:\n",
    "                continue\n",
    "            for j in range(y1,y2):\n",
    "                if j >= 416:\n",
    "                    continue\n",
    "                \n",
    "                mask_object[j][i] = [True,True,True]\n",
    "                \n",
    "    mask_background = ~mask_object\n",
    "    \n",
    "    \n",
    "    objects = np.zeros_like(IMAGE)\n",
    "    background = np.zeros_like(IMAGE)\n",
    "    \n",
    "    # Apply masks to the image to get objwct and background arrays\n",
    "    objects[mask_object] = IMAGE[mask_object]\n",
    "    background[mask_background] = IMAGE[mask_background]\n",
    "   \n",
    "    \n",
    "    return (objects, background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate the dataset for training the model later on, it is important that we set the game on the first person view and take into account certain conditions for the dataset. Check the \"How To Guide\" [here](http://www.waynenterprises.com/ai-ml) for more information on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game_control import PressKey, ReleaseKey\n",
    "from getkeys import key_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame capture functions\n",
    "These functions capture the game's frames in 1280x1024 Windowed mode.\n",
    "\n",
    "Screen record is the method to get one frame and img_thread is the thread we will later use to constantly capture the game's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global grb\n",
    "grb = Grabber(bbox=(126,26,1152,1025))\n",
    "def screen_record(method = 'ImageGrab'):\n",
    "    if method == 'ImageGrab':\n",
    "        printscreen =  ImageGrab.grab(bbox=(126,26,1152,1025))\n",
    "        generalIMG = np.array(printscreen)\n",
    "    \n",
    "    elif method == 'grabber':\n",
    "        global grb\n",
    "        printscreen = None\n",
    "        printscreen = grb.grab(printscreen)\n",
    "        generalIMG = np.array(printscreen)\n",
    "    \n",
    "    return generalIMG          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global front_buffer\n",
    "global back_buffer\n",
    "front_buffer = np.zeros((1024, 1024), dtype=np.int8)\n",
    "back_buffer = np.zeros((1024, 1024), dtype=np.int8)\n",
    "\n",
    "global fps\n",
    "fps = 0\n",
    "\n",
    "def img_thread():\n",
    "    global front_buffer\n",
    "    global back_buffer\n",
    "    global fps\n",
    "    \n",
    "    last_time = time.time()\n",
    "    while True:\n",
    "        front_buffer = screen_record()\n",
    "        # Swap buffers\n",
    "        front_buffer, back_buffer = back_buffer, front_buffer\n",
    "        fps = int(1.0/(time.time()-last_time))\n",
    "        last_time = time.time()\n",
    "        \n",
    "        if 'J' in key_check():\n",
    "            break\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a function that will apply the preprocessing we want to the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code inspired by https://towardsdatascience.com/image-pre-processing-c1aec0be3edf\n",
    "# Ideas written by Prince Canuma\n",
    "\n",
    "# adds Gaussian blur to an image\n",
    "\n",
    "def blur(res_img):\n",
    "\n",
    "    no_noise = []\n",
    "    for i in range(len(res_img)):\n",
    "        blur = cv2.GaussianBlur(res_img[i], (5, 5), 0)\n",
    "        no_noise.append(blur)\n",
    "\n",
    "    return no_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    proccessed_image = cv2.resize(image,(416,416))\n",
    "    #proccessed_image = blur(proccessed_image)\n",
    "    \n",
    "    return proccessed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game control and input reading functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions will read the inputs and generate a array for later use when generating the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_to_output(keys):\n",
    "    '''\n",
    "    Convert keys to a ...multi-hot... array\n",
    "\n",
    "    [A,W,D] boolean values.\n",
    "    '''\n",
    "    output = [0,0,0,0]\n",
    "    \n",
    "    if 'A' in keys:\n",
    "        output[0] = 1\n",
    "    if 'D' in keys:\n",
    "        output[1] = 1\n",
    "    if 'W' in keys:\n",
    "        output[2] = 1\n",
    "    if 'S' in keys:\n",
    "        output[3] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sequencer thread will capture the sequences of 5 frames with a separation of 1/capturerate ms each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global seq\n",
    "global num\n",
    "num = 0\n",
    "seq = []\n",
    "\n",
    "global key_out\n",
    "key_out = [0, 0, 0, 0]\n",
    "\n",
    "def image_sequencer_thread():\n",
    "    global back_buffer\n",
    "    global seq\n",
    "    global key_out\n",
    "    global num\n",
    "    \n",
    "    # Frames per second capture rate\n",
    "    capturerate = 10.0\n",
    "    while True:\n",
    "        last_time = time.time()\n",
    "        if len(seq) == 5:\n",
    "            del seq[0]\n",
    "\n",
    "        seq.append(preprocess_image(np.copy(back_buffer)))\n",
    "        num = num + 1\n",
    "        keys = key_check()\n",
    "        if 'J' in keys:\n",
    "            break\n",
    "        key_out = keys_to_output(keys)\n",
    "        waittime = (1.0/capturerate)-(time.time()-last_time)\n",
    "        if waittime>0.0:\n",
    "            time.sleep(waittime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be useful to check which class corresponds the input we captured to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_keys(key):\n",
    "        if np.array_equal(key , [0,0,0,0]):\n",
    "            return 0\n",
    "        elif np.array_equal(key , [1,0,0,0]):\n",
    "            return 1\n",
    "        elif np.array_equal(key , [0,1,0,0]):\n",
    "            return 2\n",
    "        elif np.array_equal(key , [0,0,1,0]):\n",
    "            return 3\n",
    "        elif np.array_equal(key , [0,0,0,1]):\n",
    "            return 4\n",
    "        elif np.array_equal(key , [1,0,1,0]):\n",
    "            return 5\n",
    "        elif np.array_equal(key , [1,0,0,1]):\n",
    "            return 6\n",
    "        elif np.array_equal(key , [0,1,1,0]):\n",
    "            return 7\n",
    "        elif np.array_equal(key , [0,1,0,1]):\n",
    "            return 8\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that the data saving threads will run to save the dataset to compressed files (change the path if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data,number):\n",
    "    file_name = 'Training_Data\\\\training_data'+str(number)+'.npz'\n",
    "    np.savez_compressed(file_name,data=list([x[:5] for x in data]),labels=list([x[5:] for x in data]))\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run this function to generate the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    global fps\n",
    "    global front_buffer\n",
    "    global back_buffer\n",
    "    global seq\n",
    "    global key_out\n",
    "    global num\n",
    "    training_data = []\n",
    "    threads = list()\n",
    "    th_img = threading.Thread(target=img_thread)\n",
    "    th_seq = threading.Thread(target=image_sequencer_thread)\n",
    "    threads.append(th_img)\n",
    "    threads.append(th_seq)\n",
    "    th_img.start()\n",
    "    time.sleep(1)\n",
    "    th_seq.start()\n",
    "    l = 0\n",
    "    fn = 0\n",
    "    time.sleep(4)\n",
    "    last_num = 0\n",
    "    \n",
    "    number_of_keys = [0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    while True:\n",
    "        img_seq = seq.copy()\n",
    "        output = key_out.copy()\n",
    "        \n",
    "        while len(img_seq) != 5 or last_num==num:\n",
    "            del img_seq, output\n",
    "            img_seq = seq.copy()\n",
    "            output = key_out.copy()\n",
    "        last_num = num\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        stdout.write('Recording at {} FPS \\n'.format(fps))\n",
    "        stdout.write('Images in sequence {} \\n'.format(len(img_seq)))\n",
    "        stdout.write('Training data len {} secuences \\n'.format(l))\n",
    "        stdout.write('Number of archives {}\\n'.format(fn))\n",
    "        stdout.write('Keys pressed: ' + str(output) + ' \\n')\n",
    "        stdout.write('Keys samples in this file: ' + 'none:' + str(number_of_keys[0]) + ' A:' + str(number_of_keys[1])+ ' D:' + str(number_of_keys[2]) + ' W:' + str(number_of_keys[3])+ ' S:' + str(number_of_keys[4]) + ' AW:'  + str(number_of_keys[5]) + ' AS:' + str(number_of_keys[6]) + ' WD:' + str(number_of_keys[7]) + ' SD:' + str(number_of_keys[8]) + ' \\n')\n",
    "        stdout.flush()\n",
    "        \n",
    "        key  = counter_keys(output)\n",
    "        \n",
    "        if key != -1:\n",
    "            larg = nlargest(9,number_of_keys)\n",
    "            prop = (9. - float(larg.index(number_of_keys[key])))/10\n",
    "            if(number_of_keys[key]  > np.mean(number_of_keys) * 1.25):\n",
    "                prop = prop + 0.05\n",
    "            if (np.random.rand() > prop):\n",
    "                number_of_keys[key] += 1\n",
    "                l = l+1\n",
    "                training_data.append([img_seq[0],img_seq[1],img_seq[2],img_seq[3],img_seq[4], output])\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        if len(training_data) % 500 == 0 and len(training_data) != 0:\n",
    "        #if len(training_data) % 20 == 0 and len(training_data) != 0:\n",
    "            threading.Thread(target=save_data, args=(training_data.copy(), fn,)).start()\n",
    "            fn = fn + 1\n",
    "            del training_data\n",
    "            training_data = []\n",
    "            \n",
    "        if 'J' in key_check():\n",
    "            threading.Thread(target=save_data, args=(training_data.copy(), fn,)).start()\n",
    "            fn = fn + 1\n",
    "            del training_data\n",
    "            training_data = []\n",
    "            break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the capture and generation of the dataset, remember that the game's window must be in 1280x1024 resolution and located in the top left part of the screen ((0,0) coordinates).\n",
    "\n",
    "Once you captured all the data you need you can press 'J' to stop the run function and archive the current sequences. Be sure to give it some time to save before shutting down the kernel, as the large files may take some time to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "capturing = False\n",
    "\n",
    "if capturing:\n",
    "    time.sleep(15)\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plots images from the data file\n",
    "Change the filepath and index 'i' if necessary\n",
    "'''\n",
    "\n",
    "plotImgs = False\n",
    "if plotImgs:\n",
    "    with np.load('D:\\\\Data\\\\Miller_Data(2)3-11-2021\\\\training_data1.npz') as data:\n",
    "        training_data = data['data']\n",
    "    \n",
    "    i= 420\n",
    "    \n",
    "    for j in range(5):\n",
    "        plt.imshow(cv2.cvtColor(training_data[i][j], cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        plt.imshow(cv2.cvtColor(training_data[i][j], cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plots images from the data file after object detection and separation\n",
    "Change the filepath and index 'i' if necessary\n",
    "'''\n",
    "\n",
    "plotImgs = False\n",
    "if plotImgs:\n",
    "    with np.load('D:\\\\Data\\\\Miller_Data(2)3-11-2021\\\\training_data1.npz') as data:\n",
    "        training_data = data['data']\n",
    "    \n",
    "    i = 420\n",
    "    \n",
    "    train_objects = []\n",
    "    train_background = []\n",
    "    for j in range(5):\n",
    "        temp1,temp2 = get_sub_images(training_data[i][j])\n",
    "        train_objects.append(temp1)\n",
    "        train_background.append(temp2)\n",
    "\n",
    "    for j in range(5):\n",
    "        plt.imshow(cv2.cvtColor(train_objects[j], cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        plt.imshow(cv2.cvtColor(train_background[j], cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to count the number of instances per class in a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_class(data, labels):\n",
    "    \n",
    "    #[nonekey,A,D,W,S,AW,AS,DW,DS]\n",
    "    imgs = [[],[],[],[],[],[],[],[],[]]\n",
    "    lbls = [[],[],[],[],[],[],[],[],[]]\n",
    "    \n",
    "    #np.random.shuffle(data)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if np.array_equal(labels[i] , [0,0,0,0]):\n",
    "            imgs[0].append(data[i])\n",
    "            lbls[0].append(labels[i])\n",
    "        elif np.array_equal(labels[i] , [1,0,0,0]):\n",
    "            imgs[1].append(data[i])\n",
    "            lbls[1].append(labels[i])\n",
    "        elif np.array_equal(labels[i] , [0,1,0,0]):\n",
    "            imgs[2].append(data[i])\n",
    "            lbls[2].append(labels[i])\n",
    "        elif np.array_equal(labels[i] , [0,0,1,0]):\n",
    "            imgs[3].append(data[i])\n",
    "            lbls[3].append(labels[i])\n",
    "        elif np.array_equal(labels[i] , [0,0,0,1]):\n",
    "            imgs[4].append(data[i])\n",
    "            lbls[4].append(labels[i])\n",
    "        elif np.array_equal(labels[i] , [1,0,1,0]):\n",
    "            imgs[5].append(data[i])\n",
    "            lbls[5].append(labels[i])\n",
    "        elif np.array_equal(labels[i] , [1,0,0,1]):\n",
    "            imgs[6].append(data[i])\n",
    "            lbls[6].append(labels[i])\n",
    "        elif np.array_equal(labels[i] , [0,1,1,0]):\n",
    "            imgs[7].append(data[i])\n",
    "            lbls[7].append(labels[i])\n",
    "        elif np.array_equal(labels[i] , [0,1,0,1]):\n",
    "            imgs[8].append(data[i])\n",
    "            lbls[8].append(labels[i])\n",
    "\n",
    "    return (imgs, lbls)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will balance the number of instances of the classes in a set by deleting extra instances after shuffling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(data_in_clases, labels_in_clases):\n",
    "    balanced_data = []\n",
    "    balanced_labels = []\n",
    "    \n",
    "    max_len = 999999999999999999999\n",
    "    for i in range(len(labels_in_clases)):\n",
    "        ln = len(labels_in_clases[i])\n",
    "        if ln < max_len:\n",
    "            max_len = ln \n",
    "    \n",
    "    for i in range(len(labels_in_clases)):\n",
    "        for j in range(max_len):\n",
    "            balanced_data.append(data_in_clases[i][j])\n",
    "            balanced_labels.append(labels_in_clases[i][j])\n",
    "    \n",
    "    \n",
    "    to_shuffle = list(zip(balanced_data, balanced_labels))\n",
    "    np.random.shuffle(to_shuffle)\n",
    "    balanced_data, balanced_labels = zip(*to_shuffle)\n",
    "    \n",
    "    return (balanced_data, balanced_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debug purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'D:\\\\Data\\\\Data-Course1\\training_data0.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b94b539cbaa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:\\Data\\Data-Course1\\training_data0.npz'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'D:\\\\Data\\\\Data-Course1\\training_data0.npz'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tests data balancing.\n",
    "Label replacement can be used to achieve an even distribution of labels among all images\n",
    "'''\n",
    "\n",
    "\n",
    "debug = True\n",
    "\n",
    "if debug:\n",
    "    with np.load('D:\\Data\\Data-Course1\\training_data0.npz') as data:\n",
    "        images = data['data']\n",
    "        labels = data['labels']\n",
    "\n",
    "    \n",
    "    labels = np.array([x[0] for x in labels])\n",
    "    \n",
    "    '''\n",
    "    # testing labels replacement\n",
    "    new_labels = []\n",
    "    for i in range(len(labels)):\n",
    "        if i%9 == 0:\n",
    "            new_labels.append([0,0,0,0])\n",
    "        if i%9 == 1:\n",
    "            new_labels.append([1,0,0,0])\n",
    "        if i%9 == 2:\n",
    "            new_labels.append([0,1,0,0])\n",
    "        if i%9 == 3:\n",
    "            new_labels.append([0,0,1,0])\n",
    "        if i%9 == 4:\n",
    "            new_labels.append([0,0,0,1])\n",
    "        if i%9 == 5:\n",
    "            new_labels.append([1,0,1,0])\n",
    "        if i%9 == 6:\n",
    "            new_labels.append([1,0,0,1])\n",
    "        if i%9 == 7:\n",
    "            new_labels.append([0,1,1,0])\n",
    "        if i%9 == 8:\n",
    "            new_labels.append([0,1,0,1])\n",
    "    labels = new_labels\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    sorted_images, sorted_labels = sort_by_class(images, labels) \n",
    "    print('none: ' + str(len(sorted_labels[0])))\n",
    "    print('A: ' + str(len(sorted_labels[1])))\n",
    "    print('D ' + str(len(sorted_labels[2])))\n",
    "    print('W ' + str(len(sorted_labels[3])))\n",
    "    print('S ' + str(len(sorted_labels[4])))\n",
    "    print('AW ' + str(len(sorted_labels[5])))\n",
    "    print('AS ' + str(len(sorted_labels[6])))\n",
    "    print('DW ' + str(len(sorted_labels[7])))\n",
    "    print('DS ' + str(len(sorted_labels[8])))\n",
    "\n",
    "\n",
    "    sorted_images, sorted_labels = balance_data(sorted_images, sorted_labels)\n",
    "    sorted_images, sorted_labels = sort_by_class(sorted_images, sorted_labels)\n",
    "    print('none: ' + str(len(sorted_labels[0])))\n",
    "    print('A: ' + str(len(sorted_labels[1])))\n",
    "    print('D ' + str(len(sorted_labels[2])))\n",
    "    print('W ' + str(len(sorted_labels[3])))\n",
    "    print('S ' + str(len(sorted_labels[4])))\n",
    "    print('AW ' + str(len(sorted_labels[5])))\n",
    "    print('AS ' + str(len(sorted_labels[6])))\n",
    "    print('DW ' + str(len(sorted_labels[7])))\n",
    "    print('DS ' + str(len(sorted_labels[8])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tests for improperly zipped data. \n",
    "This usually occurs when the saving process is interrupted or when the data is corrupted during a transfer.\n",
    "Change the folder path to the location of the data you want to test\n",
    "'''\n",
    "\n",
    "\n",
    "debug = False\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "if debug:\n",
    "    file_names = glob.glob(\"D:\\\\Data_Archive\\\\**\\*.npz\", recursive=True)\n",
    "    \n",
    "    for file in file_names:\n",
    "        try:\n",
    "            with ZipFile(file) as zf:\n",
    "                print (\"found good file: \", file)\n",
    "        except BadZipfile:\n",
    "            print (\"found bad file: \", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tests data files for an absence of a key class, which breaks the training generator.\n",
    "Change the folder path to the location of the data you want to test\n",
    "'''\n",
    "\n",
    "\n",
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    \n",
    "    file_names = glob.glob(\"D:\\\\Data_Archive\\\\**\\*.npz\", recursive=True)\n",
    "    \n",
    "    for file in file_names:\n",
    "        with np.load(file) as data:\n",
    "            images = data['data']\n",
    "            labels = data['labels']\n",
    "\n",
    "        labels = np.array([x[0] for x in labels])\n",
    "    \n",
    "        sorted_images, sorted_labels = sort_by_class(images, labels) \n",
    "        if any(len(sorted_labels[x]) == 0 for x in range(len(sorted_labels))):\n",
    "            print (\"found bad file: \", file)\n",
    "        else:\n",
    "            print (\"found good file: \", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the model to use in our training, please select the model you want to use in the cell bellow (the first two models are described in the \"Definition of the DNN\" of this [documentation](https://github.com/eritzyg/GTAV-Self-driving-car#documentation). They are kept for archiving purposes.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model to use:\n",
    "# 'CNN+MPL' : Convolutional neural network with multi layer perceptron.\n",
    "# 'CNN+RNN' : Convolutional neural network with recurrent neural network.\n",
    "# 'YOLO'    : Processes the objects and the background seperately \n",
    "selected_model = 'YOLO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we define the corresponding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model == 'CNN+RNN':\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(InputLayer(input_shape=(5, 270, 480, 3)))\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(32, (4,4), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(32, (4,4), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(16, (3,3), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(GRU(256, kernel_initializer=initializers.RandomNormal(stddev=0.001))) #128\n",
    "    model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(100))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(80))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(40))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(9, activation='sigmoid'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    opt = optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model == 'CNN+MLP':\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(InputLayer(input_shape=(5, 270, 480, 3)))\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(16, (4,8), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(16, (4,4), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(Convolution2D(12, (3,3), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Activation('relu')))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last')))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(Dense(300))\n",
    "    print(model.output_shape)\n",
    "    model.add(Dense(100))\n",
    "    print(model.output_shape)\n",
    "    print(model.output_shape)\n",
    "    model.add(Dense(9, activation='sigmoid'))\n",
    "    print(model.output_shape)\n",
    "\n",
    "    opt = optimizers.rmsprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model by Evan Miller\n",
    "#\n",
    "# Takes in two inputs corresponding to the images after they have been split into objects and background\n",
    "# by the YOLO object detection algorithm. These images are processed with a CNN and an RNN+CNN respectively, then they are\n",
    "# concatenated and fed through some Dense layers for a final prediction.\n",
    "\n",
    "if selected_model == 'YOLO':\n",
    "    input1 = tf.keras.Input(shape=(5, 416, 416, 3))\n",
    "    x1 = TimeDistributed(Convolution2D(16, (4,8), data_format='channels_last'))(input1)\n",
    "    x1 = TimeDistributed(Activation('relu'))(x1)\n",
    "    x1 = TimeDistributed(Convolution2D(16, (4,4), data_format='channels_last'))(x1)\n",
    "    x1 = TimeDistributed(Activation('relu'))(x1)\n",
    "    x1 = TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last'))(x1)\n",
    "    x1 = TimeDistributed(Dropout(0.25))(x1)\n",
    "    x1 = TimeDistributed(Convolution2D(12, (3,3), data_format='channels_last'))(x1)\n",
    "    x1 = TimeDistributed(Activation('relu'))(x1)\n",
    "    x1 = TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last'))(x1)\n",
    "    #x1 = TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last'))(x1)\n",
    "    x1 = TimeDistributed(Dropout(0.25))(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(300)(x1)\n",
    "    x1 = Dense(100)(x1)\n",
    "    #x1 = Dense(9, activation='sigmoid')(x1)\n",
    "    x1 = Model(inputs=input1,outputs=x1)\n",
    "    \n",
    "    input2 = tf.keras.Input(shape=(5, 416, 416, 3))\n",
    "    x2 = TimeDistributed(Convolution2D(32, (4,4), data_format='channels_last'))(input2)\n",
    "    x2 = TimeDistributed(Activation('relu'))(x2)\n",
    "    x2 = TimeDistributed(Convolution2D(32, (4,4), data_format='channels_last'))(x2)\n",
    "    x2 = TimeDistributed(Activation('relu'))(x2)\n",
    "    x2 = TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last'))(x2)\n",
    "    x2 = TimeDistributed(Dropout(0.25))(x2)\n",
    "    x2 = TimeDistributed(Convolution2D(16, (3,3), data_format='channels_last'))(x2)\n",
    "    x2 = TimeDistributed(Activation('relu'))(x2)\n",
    "    x2 = TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last'))(x2)\n",
    "    #x2 = TimeDistributed(MaxPooling2D(pool_size=(5, 5), data_format='channels_last'))(x2)\n",
    "    x2 = TimeDistributed(Dropout(0.25))(x2)\n",
    "    x2 = TimeDistributed(Flatten())(x2)\n",
    "    x2 = GRU(256, kernel_initializer=initializers.RandomNormal(stddev=0.001))(x2)\n",
    "    x2 = Dropout(0.25)(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(100)(x2)\n",
    "    #x2 = Dense(80)(x2)\n",
    "    #x2 = Dense(40)(x2)\n",
    "    #x2 = Dense(9, activation='sigmoid')(x2)\n",
    "    x2 = Model(inputs=input2,outputs=x2)\n",
    "    \n",
    "    combined = concatenate([x1.output,x2.output])\n",
    "    out = Dense(80)(combined)\n",
    "    out = Dense(40)(out)\n",
    "    out = Dense(9, activation='softmax')(out)\n",
    "    \n",
    "    model = Model(inputs=[x1.input,x2.input], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 5, 416, 416, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 5, 413, 413,  1568        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 5, 416, 416, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 5, 413, 413,  0           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 5, 413, 409,  1552        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 5, 410, 410,  16416       time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 5, 413, 409,  0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 5, 410, 410,  0           time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 5, 410, 406,  4112        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 5, 82, 82, 32 0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 5, 410, 406,  0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 5, 82, 82, 32 0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 5, 82, 81, 16 0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 5, 80, 80, 16 4624        time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 5, 82, 81, 16 0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 5, 80, 80, 16 0           time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 5, 80, 79, 12 1740        time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 5, 16, 16, 16 0           time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 5, 80, 79, 12 0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 5, 16, 16, 16 0           time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 5, 16, 15, 12 0           time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, 5, 4096)      0           time_distributed_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 5, 16, 15, 12 0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          3343872     time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 14400)        0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 300)          4320300     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          30100       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          25700       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 200)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           16080       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 40)           3240        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 9)            369         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,769,673\n",
      "Trainable params: 7,769,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.0001,\n",
    "    momentum=0.9,\n",
    "    centered=True,\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', weighted_metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will calculate the number of instances of each class in order to create class weights for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Data\\Data-Course1\\training_data0.npz\n",
      "none: 90\n",
      "A: 48\n",
      "D 36\n",
      "W 105\n",
      "S 56\n",
      "AW 77\n",
      "AS 14\n",
      "DW 54\n",
      "DS 20\n",
      "D:\\Data\\Data-Course1\\training_data1.npz\n",
      "none: 93\n",
      "A: 50\n",
      "D 30\n",
      "W 90\n",
      "S 46\n",
      "AW 67\n",
      "AS 19\n",
      "DW 50\n",
      "DS 17\n",
      "D:\\Data\\Data-Course2\\training_data0.npz\n",
      "none: 77\n",
      "A: 44\n",
      "D 43\n",
      "W 83\n",
      "S 65\n",
      "AW 78\n",
      "AS 22\n",
      "DW 56\n",
      "DS 32\n",
      "D:\\Data\\Data-Course2\\training_data1.npz\n",
      "none: 61\n",
      "A: 65\n",
      "D 35\n",
      "W 81\n",
      "S 66\n",
      "AW 58\n",
      "AS 39\n",
      "DW 58\n",
      "DS 37\n",
      "D:\\Data\\Data-Course2\\training_data2.npz\n",
      "none: 67\n",
      "A: 53\n",
      "D 35\n",
      "W 89\n",
      "S 59\n",
      "AW 69\n",
      "AS 37\n",
      "DW 61\n",
      "DS 30\n",
      "D:\\Data\\Data-Course2\\training_data3.npz\n",
      "none: 13\n",
      "A: 8\n",
      "D 9\n",
      "W 23\n",
      "S 28\n",
      "AW 14\n",
      "AS 20\n",
      "DW 13\n",
      "DS 8\n",
      "D:\\Data\\John\\training_data_1.npz\n",
      "none: 45\n",
      "A: 55\n",
      "D 41\n",
      "W 57\n",
      "S 41\n",
      "AW 66\n",
      "AS 46\n",
      "DW 44\n",
      "DS 9\n",
      "D:\\Data\\John\\training_data_10.npz\n",
      "none: 52\n",
      "A: 60\n",
      "D 36\n",
      "W 107\n",
      "S 55\n",
      "AW 60\n",
      "AS 48\n",
      "DW 58\n",
      "DS 24\n",
      "D:\\Data\\John\\training_data_100.npz\n",
      "none: 64\n",
      "A: 62\n",
      "D 55\n",
      "W 100\n",
      "S 44\n",
      "AW 67\n",
      "AS 34\n",
      "DW 67\n",
      "DS 7\n",
      "D:\\Data\\John\\training_data_101.npz\n",
      "none: 55\n",
      "A: 76\n",
      "D 36\n",
      "W 95\n",
      "S 56\n",
      "AW 74\n",
      "AS 33\n",
      "DW 60\n",
      "DS 15\n",
      "D:\\Data\\John\\training_data_102.npz\n",
      "none: 84\n",
      "A: 68\n",
      "D 38\n",
      "W 87\n",
      "S 32\n",
      "AW 75\n",
      "AS 30\n",
      "DW 73\n",
      "DS 13\n",
      "D:\\Data\\John\\training_data_103.npz\n",
      "none: 55\n",
      "A: 73\n",
      "D 37\n",
      "W 98\n",
      "S 36\n",
      "AW 72\n",
      "AS 41\n",
      "DW 63\n",
      "DS 25\n",
      "D:\\Data\\John\\training_data_104.npz\n",
      "none: 63\n",
      "A: 70\n",
      "D 37\n",
      "W 100\n",
      "S 28\n",
      "AW 62\n",
      "AS 68\n",
      "DW 62\n",
      "DS 10\n",
      "D:\\Data\\John\\training_data_105.npz\n",
      "none: 71\n",
      "A: 62\n",
      "D 43\n",
      "W 92\n",
      "S 35\n",
      "AW 60\n",
      "AS 54\n",
      "DW 59\n",
      "DS 24\n",
      "D:\\Data\\John\\training_data_106.npz\n",
      "none: 12\n",
      "A: 14\n",
      "D 3\n",
      "W 22\n",
      "S 5\n",
      "AW 14\n",
      "AS 11\n",
      "DW 15\n",
      "DS 24\n",
      "D:\\Data\\John\\training_data_107.npz\n",
      "none: 61\n",
      "A: 64\n",
      "D 51\n",
      "W 96\n",
      "S 46\n",
      "AW 69\n",
      "AS 38\n",
      "DW 58\n",
      "DS 17\n",
      "D:\\Data\\John\\training_data_108.npz\n",
      "none: 69\n",
      "A: 69\n",
      "D 34\n",
      "W 92\n",
      "S 34\n",
      "AW 70\n",
      "AS 34\n",
      "DW 73\n",
      "DS 25\n",
      "D:\\Data\\John\\training_data_109.npz\n",
      "none: 56\n",
      "A: 66\n",
      "D 46\n",
      "W 108\n",
      "S 43\n",
      "AW 63\n",
      "AS 49\n",
      "DW 56\n",
      "DS 13\n",
      "D:\\Data\\John\\training_data_11.npz\n",
      "none: 67\n",
      "A: 62\n",
      "D 37\n",
      "W 79\n",
      "S 46\n",
      "AW 66\n",
      "AS 67\n",
      "DW 56\n",
      "DS 20\n",
      "D:\\Data\\John\\training_data_110.npz\n",
      "none: 9\n",
      "A: 15\n",
      "D 7\n",
      "W 34\n",
      "S 6\n",
      "AW 24\n",
      "AS 21\n",
      "DW 5\n",
      "DS 5\n",
      "D:\\Data\\John\\training_data_12.npz\n",
      "none: 62\n",
      "A: 63\n",
      "D 41\n",
      "W 67\n",
      "S 82\n",
      "AW 59\n",
      "AS 43\n",
      "DW 53\n",
      "DS 30\n",
      "D:\\Data\\John\\training_data_13.npz\n",
      "none: 76\n",
      "A: 60\n",
      "D 39\n",
      "W 92\n",
      "S 42\n",
      "AW 81\n",
      "AS 22\n",
      "DW 77\n",
      "DS 11\n",
      "D:\\Data\\John\\training_data_14.npz\n",
      "none: 62\n",
      "A: 48\n",
      "D 34\n",
      "W 76\n",
      "S 52\n",
      "AW 69\n",
      "AS 81\n",
      "DW 51\n",
      "DS 27\n",
      "D:\\Data\\John\\training_data_15.npz\n",
      "none: 83\n",
      "A: 45\n",
      "D 42\n",
      "W 83\n",
      "S 65\n",
      "AW 74\n",
      "AS 40\n",
      "DW 61\n",
      "DS 7\n",
      "D:\\Data\\John\\training_data_16.npz\n",
      "none: 53\n",
      "A: 66\n",
      "D 35\n",
      "W 95\n",
      "S 53\n",
      "AW 64\n",
      "AS 55\n",
      "DW 49\n",
      "DS 30\n",
      "D:\\Data\\John\\training_data_17.npz\n",
      "none: 18\n",
      "A: 35\n",
      "D 27\n",
      "W 45\n",
      "S 35\n",
      "AW 39\n",
      "AS 22\n",
      "DW 39\n",
      "DS 15\n",
      "D:\\Data\\John\\training_data_18.npz\n",
      "none: 65\n",
      "A: 62\n",
      "D 40\n",
      "W 93\n",
      "S 42\n",
      "AW 72\n",
      "AS 42\n",
      "DW 57\n",
      "DS 27\n",
      "D:\\Data\\John\\training_data_19.npz\n",
      "none: 63\n",
      "A: 49\n",
      "D 40\n",
      "W 94\n",
      "S 60\n",
      "AW 59\n",
      "AS 53\n",
      "DW 49\n",
      "DS 33\n",
      "D:\\Data\\John\\training_data_2.npz\n",
      "none: 63\n",
      "A: 51\n",
      "D 45\n",
      "W 98\n",
      "S 45\n",
      "AW 63\n",
      "AS 59\n",
      "DW 61\n",
      "DS 15\n",
      "D:\\Data\\John\\training_data_20.npz\n",
      "none: 60\n",
      "A: 55\n",
      "D 42\n",
      "W 93\n",
      "S 61\n",
      "AW 68\n",
      "AS 34\n",
      "DW 62\n",
      "DS 25\n",
      "D:\\Data\\John\\training_data_21.npz\n",
      "none: 41\n",
      "A: 64\n",
      "D 41\n",
      "W 99\n",
      "S 52\n",
      "AW 66\n",
      "AS 55\n",
      "DW 58\n",
      "DS 24\n",
      "D:\\Data\\John\\training_data_23.npz\n",
      "none: 53\n",
      "A: 57\n",
      "D 37\n",
      "W 105\n",
      "S 41\n",
      "AW 70\n",
      "AS 54\n",
      "DW 52\n",
      "DS 31\n",
      "D:\\Data\\John\\training_data_24.npz\n",
      "none: 57\n",
      "A: 57\n",
      "D 43\n",
      "W 79\n",
      "S 58\n",
      "AW 62\n",
      "AS 58\n",
      "DW 58\n",
      "DS 28\n",
      "D:\\Data\\John\\training_data_25.npz\n",
      "none: 57\n",
      "A: 54\n",
      "D 26\n",
      "W 93\n",
      "S 50\n",
      "AW 77\n",
      "AS 53\n",
      "DW 53\n",
      "DS 37\n",
      "D:\\Data\\John\\training_data_26.npz\n",
      "none: 34\n",
      "A: 38\n",
      "D 16\n",
      "W 64\n",
      "S 33\n",
      "AW 43\n",
      "AS 21\n",
      "DW 35\n",
      "DS 30\n",
      "D:\\Data\\John\\training_data_27.npz\n",
      "none: 22\n",
      "A: 35\n",
      "D 23\n",
      "W 49\n",
      "S 28\n",
      "AW 40\n",
      "AS 38\n",
      "DW 31\n",
      "DS 39\n",
      "D:\\Data\\John\\training_data_28.npz\n",
      "none: 64\n",
      "A: 57\n",
      "D 38\n",
      "W 100\n",
      "S 33\n",
      "AW 65\n",
      "AS 57\n",
      "DW 58\n",
      "DS 28\n",
      "D:\\Data\\John\\training_data_29.npz\n",
      "none: 54\n",
      "A: 59\n",
      "D 33\n",
      "W 85\n",
      "S 34\n",
      "AW 78\n",
      "AS 59\n",
      "DW 61\n",
      "DS 37\n",
      "D:\\Data\\John\\training_data_3.npz\n",
      "none: 52\n",
      "A: 66\n",
      "D 33\n",
      "W 96\n",
      "S 53\n",
      "AW 54\n",
      "AS 56\n",
      "DW 56\n",
      "DS 34\n",
      "D:\\Data\\John\\training_data_30.npz\n",
      "none: 46\n",
      "A: 49\n",
      "D 37\n",
      "W 106\n",
      "S 51\n",
      "AW 54\n",
      "AS 60\n",
      "DW 57\n",
      "DS 40\n",
      "D:\\Data\\John\\training_data_33.npz\n",
      "none: 57\n",
      "A: 55\n",
      "D 34\n",
      "W 121\n",
      "S 48\n",
      "AW 69\n",
      "AS 32\n",
      "DW 49\n",
      "DS 35\n",
      "D:\\Data\\John\\training_data_34.npz\n",
      "none: 56\n",
      "A: 57\n",
      "D 38\n",
      "W 109\n",
      "S 52\n",
      "AW 60\n",
      "AS 55\n",
      "DW 57\n",
      "DS 16\n",
      "D:\\Data\\John\\training_data_38.npz\n",
      "none: 72\n",
      "A: 57\n",
      "D 52\n",
      "W 93\n",
      "S 46\n",
      "AW 57\n",
      "AS 41\n",
      "DW 59\n",
      "DS 23\n",
      "D:\\Data\\John\\training_data_39.npz\n",
      "none: 50\n",
      "A: 56\n",
      "D 51\n",
      "W 90\n",
      "S 36\n",
      "AW 62\n",
      "AS 69\n",
      "DW 57\n",
      "DS 29\n",
      "D:\\Data\\John\\training_data_4.npz\n",
      "none: 62\n",
      "A: 56\n",
      "D 47\n",
      "W 94\n",
      "S 56\n",
      "AW 66\n",
      "AS 48\n",
      "DW 61\n",
      "DS 10\n",
      "D:\\Data\\John\\training_data_40.npz\n",
      "none: 47\n",
      "A: 49\n",
      "D 27\n",
      "W 86\n",
      "S 52\n",
      "AW 59\n",
      "AS 73\n",
      "DW 60\n",
      "DS 47\n",
      "D:\\Data\\John\\training_data_41.npz\n",
      "none: 63\n",
      "A: 60\n",
      "D 53\n",
      "W 74\n",
      "S 33\n",
      "AW 60\n",
      "AS 48\n",
      "DW 61\n",
      "DS 48\n",
      "D:\\Data\\John\\training_data_43.npz\n",
      "none: 53\n",
      "A: 61\n",
      "D 40\n",
      "W 80\n",
      "S 50\n",
      "AW 65\n",
      "AS 62\n",
      "DW 54\n",
      "DS 35\n",
      "D:\\Data\\John\\training_data_44.npz\n",
      "none: 65\n",
      "A: 57\n",
      "D 52\n",
      "W 71\n",
      "S 51\n",
      "AW 71\n",
      "AS 47\n",
      "DW 55\n",
      "DS 31\n",
      "D:\\Data\\John\\training_data_45.npz\n",
      "none: 54\n",
      "A: 67\n",
      "D 49\n",
      "W 74\n",
      "S 45\n",
      "AW 60\n",
      "AS 56\n",
      "DW 62\n",
      "DS 33\n",
      "D:\\Data\\John\\training_data_46.npz\n",
      "none: 52\n",
      "A: 48\n",
      "D 33\n",
      "W 84\n",
      "S 39\n",
      "AW 79\n",
      "AS 65\n",
      "DW 53\n",
      "DS 47\n",
      "D:\\Data\\John\\training_data_47.npz\n",
      "none: 57\n",
      "A: 50\n",
      "D 53\n",
      "W 85\n",
      "S 35\n",
      "AW 72\n",
      "AS 56\n",
      "DW 56\n",
      "DS 36\n",
      "D:\\Data\\John\\training_data_48.npz\n",
      "none: 60\n",
      "A: 63\n",
      "D 43\n",
      "W 84\n",
      "S 46\n",
      "AW 64\n",
      "AS 50\n",
      "DW 62\n",
      "DS 28\n",
      "D:\\Data\\John\\training_data_49.npz\n",
      "none: 51\n",
      "A: 52\n",
      "D 38\n",
      "W 87\n",
      "S 45\n",
      "AW 83\n",
      "AS 56\n",
      "DW 52\n",
      "DS 36\n",
      "D:\\Data\\John\\training_data_5.npz\n",
      "none: 54\n",
      "A: 61\n",
      "D 63\n",
      "W 77\n",
      "S 54\n",
      "AW 55\n",
      "AS 66\n",
      "DW 60\n",
      "DS 10\n",
      "D:\\Data\\John\\training_data_51.npz\n",
      "none: 23\n",
      "A: 21\n",
      "D 11\n",
      "W 36\n",
      "S 10\n",
      "AW 30\n",
      "AS 20\n",
      "DW 21\n",
      "DS 21\n",
      "D:\\Data\\John\\training_data_52.npz\n",
      "none: 60\n",
      "A: 60\n",
      "D 38\n",
      "W 107\n",
      "S 33\n",
      "AW 66\n",
      "AS 46\n",
      "DW 61\n",
      "DS 29\n",
      "D:\\Data\\John\\training_data_53.npz\n",
      "none: 45\n",
      "A: 65\n",
      "D 47\n",
      "W 103\n",
      "S 53\n",
      "AW 70\n",
      "AS 57\n",
      "DW 47\n",
      "DS 13\n",
      "D:\\Data\\John\\training_data_54.npz\n",
      "none: 57\n",
      "A: 40\n",
      "D 26\n",
      "W 98\n",
      "S 37\n",
      "AW 71\n",
      "AS 57\n",
      "DW 54\n",
      "DS 60\n",
      "D:\\Data\\John\\training_data_55.npz\n",
      "none: 53\n",
      "A: 58\n",
      "D 27\n",
      "W 99\n",
      "S 71\n",
      "AW 69\n",
      "AS 38\n",
      "DW 48\n",
      "DS 37\n",
      "D:\\Data\\John\\training_data_56.npz\n",
      "none: 72\n",
      "A: 61\n",
      "D 36\n",
      "W 86\n",
      "S 44\n",
      "AW 75\n",
      "AS 46\n",
      "DW 55\n",
      "DS 25\n",
      "D:\\Data\\John\\training_data_57.npz\n",
      "none: 63\n",
      "A: 58\n",
      "D 50\n",
      "W 86\n",
      "S 40\n",
      "AW 63\n",
      "AS 50\n",
      "DW 63\n",
      "DS 27\n",
      "D:\\Data\\John\\training_data_59.npz\n",
      "none: 59\n",
      "A: 65\n",
      "D 28\n",
      "W 100\n",
      "S 47\n",
      "AW 66\n",
      "AS 52\n",
      "DW 60\n",
      "DS 23\n",
      "D:\\Data\\John\\training_data_6.npz\n",
      "none: 55\n",
      "A: 52\n",
      "D 51\n",
      "W 82\n",
      "S 67\n",
      "AW 58\n",
      "AS 53\n",
      "DW 49\n",
      "DS 33\n",
      "D:\\Data\\John\\training_data_60.npz\n",
      "none: 70\n",
      "A: 70\n",
      "D 53\n",
      "W 93\n",
      "S 37\n",
      "AW 71\n",
      "AS 27\n",
      "DW 67\n",
      "DS 12\n",
      "D:\\Data\\John\\training_data_61.npz\n",
      "none: 62\n",
      "A: 63\n",
      "D 43\n",
      "W 93\n",
      "S 41\n",
      "AW 66\n",
      "AS 54\n",
      "DW 59\n",
      "DS 19\n",
      "D:\\Data\\John\\training_data_63.npz\n",
      "none: 58\n",
      "A: 54\n",
      "D 40\n",
      "W 75\n",
      "S 36\n",
      "AW 55\n",
      "AS 38\n",
      "DW 47\n",
      "DS 17\n",
      "D:\\Data\\John\\training_data_64.npz\n",
      "none: 61\n",
      "A: 68\n",
      "D 36\n",
      "W 94\n",
      "S 36\n",
      "AW 70\n",
      "AS 48\n",
      "DW 54\n",
      "DS 33\n",
      "D:\\Data\\John\\training_data_65.npz\n",
      "none: 46\n",
      "A: 54\n",
      "D 58\n",
      "W 97\n",
      "S 36\n",
      "AW 69\n",
      "AS 62\n",
      "DW 60\n",
      "DS 18\n",
      "D:\\Data\\John\\training_data_66.npz\n",
      "none: 67\n",
      "A: 65\n",
      "D 51\n",
      "W 91\n",
      "S 35\n",
      "AW 66\n",
      "AS 51\n",
      "DW 56\n",
      "DS 18\n",
      "D:\\Data\\John\\training_data_67.npz\n",
      "none: 66\n",
      "A: 71\n",
      "D 53\n",
      "W 92\n",
      "S 35\n",
      "AW 75\n",
      "AS 29\n",
      "DW 68\n",
      "DS 11\n",
      "D:\\Data\\John\\training_data_68.npz\n",
      "none: 58\n",
      "A: 65\n",
      "D 41\n",
      "W 103\n",
      "S 40\n",
      "AW 64\n",
      "AS 55\n",
      "DW 58\n",
      "DS 16\n",
      "D:\\Data\\John\\training_data_69.npz\n",
      "none: 66\n",
      "A: 65\n",
      "D 45\n",
      "W 92\n",
      "S 46\n",
      "AW 56\n",
      "AS 59\n",
      "DW 57\n",
      "DS 14\n",
      "D:\\Data\\John\\training_data_7.npz\n",
      "none: 59\n",
      "A: 62\n",
      "D 42\n",
      "W 74\n",
      "S 45\n",
      "AW 65\n",
      "AS 62\n",
      "DW 58\n",
      "DS 33\n",
      "D:\\Data\\John\\training_data_70.npz\n",
      "none: 50\n",
      "A: 72\n",
      "D 49\n",
      "W 104\n",
      "S 54\n",
      "AW 65\n",
      "AS 45\n",
      "DW 42\n",
      "DS 19\n",
      "D:\\Data\\John\\training_data_71.npz\n",
      "none: 26\n",
      "A: 31\n",
      "D 13\n",
      "W 41\n",
      "S 20\n",
      "AW 39\n",
      "AS 25\n",
      "DW 21\n",
      "DS 2\n",
      "D:\\Data\\John\\training_data_72.npz\n",
      "none: 54\n",
      "A: 61\n",
      "D 45\n",
      "W 95\n",
      "S 38\n",
      "AW 72\n",
      "AS 53\n",
      "DW 53\n",
      "DS 29\n",
      "D:\\Data\\John\\training_data_73.npz\n",
      "none: 52\n",
      "A: 76\n",
      "D 50\n",
      "W 77\n",
      "S 59\n",
      "AW 69\n",
      "AS 48\n",
      "DW 54\n",
      "DS 15\n",
      "D:\\Data\\John\\training_data_75.npz\n",
      "none: 48\n",
      "A: 58\n",
      "D 45\n",
      "W 105\n",
      "S 47\n",
      "AW 70\n",
      "AS 53\n",
      "DW 55\n",
      "DS 19\n",
      "D:\\Data\\John\\training_data_76.npz\n",
      "none: 59\n",
      "A: 46\n",
      "D 42\n",
      "W 108\n",
      "S 50\n",
      "AW 67\n",
      "AS 54\n",
      "DW 53\n",
      "DS 21\n",
      "D:\\Data\\John\\training_data_77.npz\n",
      "none: 47\n",
      "A: 57\n",
      "D 45\n",
      "W 99\n",
      "S 44\n",
      "AW 74\n",
      "AS 51\n",
      "DW 52\n",
      "DS 31\n",
      "D:\\Data\\John\\training_data_78.npz\n",
      "none: 41\n",
      "A: 59\n",
      "D 46\n",
      "W 94\n",
      "S 43\n",
      "AW 71\n",
      "AS 55\n",
      "DW 56\n",
      "DS 35\n",
      "D:\\Data\\John\\training_data_79.npz\n",
      "none: 58\n",
      "A: 65\n",
      "D 42\n",
      "W 91\n",
      "S 47\n",
      "AW 52\n",
      "AS 51\n",
      "DW 57\n",
      "DS 37\n",
      "D:\\Data\\John\\training_data_8.npz\n",
      "none: 65\n",
      "A: 62\n",
      "D 61\n",
      "W 78\n",
      "S 49\n",
      "AW 54\n",
      "AS 44\n",
      "DW 67\n",
      "DS 20\n",
      "D:\\Data\\John\\training_data_80.npz\n",
      "none: 45\n",
      "A: 61\n",
      "D 40\n",
      "W 82\n",
      "S 51\n",
      "AW 61\n",
      "AS 60\n",
      "DW 53\n",
      "DS 47\n",
      "D:\\Data\\John\\training_data_81.npz\n",
      "none: 53\n",
      "A: 64\n",
      "D 32\n",
      "W 83\n",
      "S 50\n",
      "AW 66\n",
      "AS 54\n",
      "DW 63\n",
      "DS 35\n",
      "D:\\Data\\John\\training_data_82.npz\n",
      "none: 79\n",
      "A: 44\n",
      "D 32\n",
      "W 80\n",
      "S 42\n",
      "AW 77\n",
      "AS 58\n",
      "DW 53\n",
      "DS 20\n",
      "D:\\Data\\John\\training_data_83.npz\n",
      "none: 44\n",
      "A: 59\n",
      "D 32\n",
      "W 110\n",
      "S 49\n",
      "AW 66\n",
      "AS 55\n",
      "DW 59\n",
      "DS 26\n",
      "D:\\Data\\John\\training_data_84.npz\n",
      "none: 58\n",
      "A: 59\n",
      "D 35\n",
      "W 98\n",
      "S 48\n",
      "AW 72\n",
      "AS 47\n",
      "DW 50\n",
      "DS 33\n",
      "D:\\Data\\John\\training_data_85.npz\n",
      "none: 6\n",
      "A: 9\n",
      "D 5\n",
      "W 15\n",
      "S 6\n",
      "AW 18\n",
      "AS 7\n",
      "DW 14\n",
      "DS 15\n",
      "D:\\Data\\John\\training_data_86.npz\n",
      "none: 52\n",
      "A: 61\n",
      "D 35\n",
      "W 99\n",
      "S 50\n",
      "AW 68\n",
      "AS 33\n",
      "DW 58\n",
      "DS 44\n",
      "D:\\Data\\John\\training_data_87.npz\n",
      "none: 58\n",
      "A: 56\n",
      "D 28\n",
      "W 88\n",
      "S 49\n",
      "AW 69\n",
      "AS 80\n",
      "DW 52\n",
      "DS 20\n",
      "D:\\Data\\John\\training_data_88.npz\n",
      "none: 49\n",
      "A: 80\n",
      "D 51\n",
      "W 84\n",
      "S 58\n",
      "AW 72\n",
      "AS 45\n",
      "DW 47\n",
      "DS 14\n",
      "D:\\Data\\John\\training_data_89.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none: 55\n",
      "A: 64\n",
      "D 41\n",
      "W 83\n",
      "S 47\n",
      "AW 86\n",
      "AS 45\n",
      "DW 57\n",
      "DS 22\n",
      "D:\\Data\\John\\training_data_9.npz\n",
      "none: 25\n",
      "A: 28\n",
      "D 21\n",
      "W 43\n",
      "S 25\n",
      "AW 33\n",
      "AS 24\n",
      "DW 23\n",
      "DS 34\n",
      "D:\\Data\\John\\training_data_90.npz\n",
      "none: 14\n",
      "A: 9\n",
      "D 6\n",
      "W 24\n",
      "S 25\n",
      "AW 12\n",
      "AS 21\n",
      "DW 15\n",
      "DS 2\n",
      "D:\\Data\\John\\training_data_91.npz\n",
      "none: 60\n",
      "A: 64\n",
      "D 30\n",
      "W 91\n",
      "S 47\n",
      "AW 72\n",
      "AS 54\n",
      "DW 61\n",
      "DS 21\n",
      "D:\\Data\\John\\training_data_92.npz\n",
      "none: 53\n",
      "A: 49\n",
      "D 41\n",
      "W 106\n",
      "S 65\n",
      "AW 56\n",
      "AS 49\n",
      "DW 49\n",
      "DS 32\n",
      "D:\\Data\\John\\training_data_93.npz\n",
      "none: 48\n",
      "A: 57\n",
      "D 27\n",
      "W 97\n",
      "S 58\n",
      "AW 72\n",
      "AS 39\n",
      "DW 59\n",
      "DS 43\n",
      "D:\\Data\\John\\training_data_94.npz\n",
      "none: 66\n",
      "A: 68\n",
      "D 39\n",
      "W 81\n",
      "S 49\n",
      "AW 64\n",
      "AS 40\n",
      "DW 70\n",
      "DS 23\n",
      "D:\\Data\\John\\training_data_95.npz\n",
      "none: 59\n",
      "A: 62\n",
      "D 51\n",
      "W 81\n",
      "S 43\n",
      "AW 51\n",
      "AS 70\n",
      "DW 61\n",
      "DS 22\n",
      "D:\\Data\\John\\training_data_96.npz\n",
      "none: 70\n",
      "A: 57\n",
      "D 38\n",
      "W 118\n",
      "S 48\n",
      "AW 62\n",
      "AS 35\n",
      "DW 53\n",
      "DS 19\n",
      "D:\\Data\\John\\training_data_97.npz\n",
      "none: 11\n",
      "A: 18\n",
      "D 10\n",
      "W 16\n",
      "S 4\n",
      "AW 12\n",
      "AS 12\n",
      "DW 14\n",
      "DS 7\n",
      "D:\\Data\\John\\training_data_98.npz\n",
      "none: 60\n",
      "A: 56\n",
      "D 46\n",
      "W 110\n",
      "S 50\n",
      "AW 66\n",
      "AS 45\n",
      "DW 55\n",
      "DS 12\n",
      "D:\\Data\\John\\training_data_99.npz\n",
      "none: 61\n",
      "A: 67\n",
      "D 52\n",
      "W 92\n",
      "S 54\n",
      "AW 59\n",
      "AS 40\n",
      "DW 62\n",
      "DS 13\n",
      "D:\\Data\\Miller_Data(1)3-11-2021\\training_data0(1).npz\n",
      "none: 39\n",
      "A: 43\n",
      "D 35\n",
      "W 110\n",
      "S 20\n",
      "AW 83\n",
      "AS 53\n",
      "DW 60\n",
      "DS 57\n",
      "D:\\Data\\Miller_Data(1)3-11-2021\\training_data0.npz\n",
      "none: 49\n",
      "A: 59\n",
      "D 32\n",
      "W 93\n",
      "S 47\n",
      "AW 66\n",
      "AS 61\n",
      "DW 58\n",
      "DS 35\n",
      "D:\\Data\\Miller_Data(1)3-11-2021\\training_data1.npz\n",
      "none: 54\n",
      "A: 50\n",
      "D 37\n",
      "W 100\n",
      "S 56\n",
      "AW 77\n",
      "AS 55\n",
      "DW 62\n",
      "DS 9\n",
      "D:\\Data\\Miller_Data(2)3-11-2021\\training_data0.npz\n",
      "none: 49\n",
      "A: 57\n",
      "D 34\n",
      "W 93\n",
      "S 55\n",
      "AW 68\n",
      "AS 47\n",
      "DW 57\n",
      "DS 40\n",
      "D:\\Data\\Miller_Data(2)3-11-2021\\training_data1.npz\n",
      "none: 49\n",
      "A: 45\n",
      "D 37\n",
      "W 94\n",
      "S 43\n",
      "AW 59\n",
      "AS 66\n",
      "DW 52\n",
      "DS 55\n"
     ]
    }
   ],
   "source": [
    "Totalling = False\n",
    "\n",
    "if Totalling:\n",
    "    file_names = glob.glob(\"D:\\\\Data\\\\**\\*.npz\", recursive=True)\n",
    "    totals = [0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    for fil in file_names:\n",
    "        print(fil)\n",
    "        with np.load(fil) as dat:\n",
    "            training_data_images = dat['data']\n",
    "            training_data_labels = dat['labels']\n",
    "        \n",
    "        training_data_labels = np.array([x[0] for x in training_data_labels])\n",
    "\n",
    "        sorted_images, sorted_labels = sort_by_class(training_data_images, training_data_labels)\n",
    "        \n",
    "        print('none: ' + str(len(sorted_labels[0])))\n",
    "        print('A: ' + str(len(sorted_labels[1])))\n",
    "        print('D ' + str(len(sorted_labels[2])))\n",
    "        print('W ' + str(len(sorted_labels[3])))\n",
    "        print('S ' + str(len(sorted_labels[4])))\n",
    "        print('AW ' + str(len(sorted_labels[5])))\n",
    "        print('AS ' + str(len(sorted_labels[6])))\n",
    "        print('DW ' + str(len(sorted_labels[7])))\n",
    "        print('DS ' + str(len(sorted_labels[8])))\n",
    "\n",
    "        for i in range(len(sorted_labels)):\n",
    "            totals[i] += len(sorted_labels[i])\n",
    "\n",
    "    weights = [x/np.min(totals) for x in totals]\n",
    "    class_weights = {0:weights[0], 1:weights[1], 2:weights[2], 3:weights[3], 4:weights[4], 5:weights[5], 6:weights[6], 7:weights[7], 8:weights[8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define some functions to reshape the data according to the input of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_custom_X(data, verbose = 0):\n",
    "    reshaped = np.zeros((data.shape[0], 5, 416, 416, 3), dtype=np.float32)\n",
    "    for i in range(0, data.shape[0]):\n",
    "        for j in range(0, 5):\n",
    "            if (verbose == 1):\n",
    "                print('Reshaped image: ' + str(i))\n",
    "            reshaped[i][j] = data[i][j]\n",
    "            \n",
    "    return reshaped\n",
    "\n",
    "def reshape_custom_y(data):\n",
    "    reshaped = np.zeros((data.shape[0], 9), dtype=np.float32)\n",
    "    for i in range(0, data.shape[0]):\n",
    "        # [A,D,W,S]\n",
    "        if np.array_equal(data[i] , [0,0,0,0]):\n",
    "            reshaped[i][0] = 1.\n",
    "        elif np.array_equal(data[i] , [1,0,0,0]):\n",
    "            reshaped[i][1] = 1.\n",
    "        elif np.array_equal(data[i] , [0,1,0,0]):\n",
    "            reshaped[i][2] = 1.\n",
    "        elif np.array_equal(data[i] , [0,0,1,0]):\n",
    "            reshaped[i][3] = 1.\n",
    "        elif np.array_equal(data[i] , [0,0,0,1]):\n",
    "            reshaped[i][4] = 1.\n",
    "        elif np.array_equal(data[i] , [1,0,1,0]):\n",
    "            reshaped[i][5] = 1.\n",
    "        elif np.array_equal(data[i] , [1,0,0,1]):\n",
    "            reshaped[i][6] = 1.\n",
    "        elif np.array_equal(data[i] , [0,1,1,0]):\n",
    "            reshaped[i][7] = 1.\n",
    "        elif np.array_equal(data[i] , [0,1,0,1]):\n",
    "            reshaped[i][8] = 1.\n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we run the training process, the accuracy can be seen after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_data_generator(file_list, batch_size = 5):\n",
    "    i = 0 # Iterates over the files in the dataset\n",
    "    data = [[],[]]\n",
    "    labels = []\n",
    "    while True:\n",
    "        if i >= len(file_list):\n",
    "            print(\"\\nShuffling and Restarting...\")\n",
    "            i = 0\n",
    "            np.random.shuffle(file_list)\n",
    "        else:\n",
    "            fil = file_list[i] \n",
    "            print(\"\\nOpening Training File: \", fil)\n",
    "\n",
    "            with np.load(fil) as dat:\n",
    "                training_data_images = dat['data']\n",
    "                training_data_labels = dat['labels']\n",
    "\n",
    "            to_shuffle = list(zip(training_data_images, training_data_labels))\n",
    "            np.random.shuffle(to_shuffle)\n",
    "            training_data_images, training_data_labels = zip(*to_shuffle)\n",
    "\n",
    "            training_data_labels = np.array([x[0] for x in training_data_labels])\n",
    "\n",
    "            sorted_images, sorted_labels = sort_by_class(training_data_images, training_data_labels)\n",
    "\n",
    "            print('none: ' + str(len(sorted_labels[0])))\n",
    "            print('A: ' + str(len(sorted_labels[1])))\n",
    "            print('D ' + str(len(sorted_labels[2])))\n",
    "            print('W ' + str(len(sorted_labels[3])))\n",
    "            print('S ' + str(len(sorted_labels[4])))\n",
    "            print('AW ' + str(len(sorted_labels[5])))\n",
    "            print('AS ' + str(len(sorted_labels[6])))\n",
    "            print('DW ' + str(len(sorted_labels[7])))\n",
    "            print('DS ' + str(len(sorted_labels[8])))\n",
    "\n",
    "            # shuffling occurs here\n",
    "            #training_data_images, training_data_labels = balance_data(sorted_images, sorted_labels)\n",
    "\n",
    "            train_objects = []\n",
    "            train_background = []\n",
    "            for k in range(len(training_data_images)):\n",
    "                train_objects.append([])\n",
    "                train_background.append([])\n",
    "                for j in range(5):\n",
    "                    #normalization occurs here\n",
    "                    temp1,temp2 = get_sub_images(training_data_images[k][j])\n",
    "                    train_objects[k].append(temp1)\n",
    "                    train_background[k].append(temp2)\n",
    "\n",
    "            \n",
    "            X_train = [reshape_custom_X(np.array(train_objects)), reshape_custom_X(np.array(train_background))]\n",
    "            y_train = reshape_custom_y(np.array(training_data_labels))\n",
    "\n",
    "            # Adds data from the file to the collected data\n",
    "            for x in range(len(X_train[0])):\n",
    "                data[0].append(X_train[0][x])\n",
    "                data[1].append(X_train[1][x])\n",
    "                labels.append(y_train[x])\n",
    "                # Outputs a batch of data once a batch has been filled\n",
    "                if len(labels) >= batch_size:\n",
    "                    num_batches = len(labels) // batch_size\n",
    "                    for l in range(num_batches):\n",
    "                        yield (np.array(data[0][l*batch_size:(l+1)*batch_size]), np.array(data[1][l*batch_size:(l+1)*batch_size])), labels[l*batch_size:(l+1)*batch_size]\n",
    "                    data = [[],[]]\n",
    "                    labels = []\n",
    "            \n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training files =  88 \n",
      "number of validation files =  22\n",
      "steps_per_epoch =  39600\n",
      "validation_steps =  9900\n",
      "Epoch 1/5\n",
      "\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_73.npz'\n",
      "none: 52\n",
      "A: 76\n",
      "D 50\n",
      "W 77\n",
      "S 59\n",
      "AW 69\n",
      "AS 48\n",
      "DW 54\n",
      "DS 15\n",
      "  500/39600 [..............................] - ETA: 32:35 - loss: 5.3051 - accuracy: 0.1507\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_88.npz'\n",
      "none: 49\n",
      "A: 80\n",
      "D 51\n",
      "W 84\n",
      "S 58\n",
      "AW 72\n",
      "AS 45\n",
      "DW 47\n",
      "DS 14\n",
      "  999/39600 [..............................] - ETA: 3:14:01 - loss: 5.0638 - accuracy: 0.1860\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_11.npz'\n",
      "none: 67\n",
      "A: 62\n",
      "D 37\n",
      "W 79\n",
      "S 46\n",
      "AW 66\n",
      "AS 67\n",
      "DW 56\n",
      "DS 20\n",
      " 1500/39600 [>.............................] - ETA: 4:05:54 - loss: 4.9684 - accuracy: 0.2055\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_15.npz'\n",
      "none: 83\n",
      "A: 45\n",
      "D 42\n",
      "W 83\n",
      "S 65\n",
      "AW 74\n",
      "AS 40\n",
      "DW 61\n",
      "DS 7\n",
      " 1999/39600 [>.............................] - ETA: 4:28:21 - loss: 4.9230 - accuracy: 0.2134\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_14.npz'\n",
      "none: 62\n",
      "A: 48\n",
      "D 34\n",
      "W 76\n",
      "S 52\n",
      "AW 69\n",
      "AS 81\n",
      "DW 51\n",
      "DS 27\n",
      " 2499/39600 [>.............................] - ETA: 4:39:51 - loss: 4.8924 - accuracy: 0.2182\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_86.npz'\n",
      "none: 52\n",
      "A: 61\n",
      "D 35\n",
      "W 99\n",
      "S 50\n",
      "AW 68\n",
      "AS 33\n",
      "DW 58\n",
      "DS 44\n",
      " 2999/39600 [=>............................] - ETA: 4:47:00 - loss: 4.8679 - accuracy: 0.2218\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_33.npz'\n",
      "none: 57\n",
      "A: 55\n",
      "D 34\n",
      "W 121\n",
      "S 48\n",
      "AW 69\n",
      "AS 32\n",
      "DW 49\n",
      "DS 35\n",
      " 3499/39600 [=>............................] - ETA: 4:50:44 - loss: 4.8493 - accuracy: 0.2256\n",
      "Opening Training File:  b'D:\\\\Data\\\\Data-Course1\\\\training_data1.npz'\n",
      "none: 93\n",
      "A: 50\n",
      "D 30\n",
      "W 90\n",
      "S 46\n",
      "AW 67\n",
      "AS 19\n",
      "DW 50\n",
      "DS 17\n",
      " 3961/39600 [==>...........................] - ETA: 4:51:04 - loss: 4.8345 - accuracy: 0.2294\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_67.npz'\n",
      "none: 66\n",
      "A: 71\n",
      "D 53\n",
      "W 92\n",
      "S 35\n",
      "AW 75\n",
      "AS 29\n",
      "DW 68\n",
      "DS 11\n",
      " 4462/39600 [==>...........................] - ETA: 4:50:59 - loss: 4.8217 - accuracy: 0.2323\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_109.npz'\n",
      "none: 56\n",
      "A: 66\n",
      "D 46\n",
      "W 108\n",
      "S 43\n",
      "AW 63\n",
      "AS 49\n",
      "DW 56\n",
      "DS 13\n",
      " 4962/39600 [==>...........................] - ETA: 4:49:41 - loss: 4.8096 - accuracy: 0.2350\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_65.npz'\n",
      "none: 46\n",
      "A: 54\n",
      "D 58\n",
      "W 97\n",
      "S 36\n",
      "AW 69\n",
      "AS 62\n",
      "DW 60\n",
      "DS 18\n",
      " 5462/39600 [===>..........................] - ETA: 4:47:44 - loss: 4.7977 - accuracy: 0.2376\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_16.npz'\n",
      "none: 53\n",
      "A: 66\n",
      "D 35\n",
      "W 95\n",
      "S 53\n",
      "AW 64\n",
      "AS 55\n",
      "DW 49\n",
      "DS 30\n",
      " 5962/39600 [===>..........................] - ETA: 4:45:52 - loss: 4.7868 - accuracy: 0.2400\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_43.npz'\n",
      "none: 53\n",
      "A: 61\n",
      "D 40\n",
      "W 80\n",
      "S 50\n",
      "AW 65\n",
      "AS 62\n",
      "DW 54\n",
      "DS 35\n",
      " 6462/39600 [===>..........................] - ETA: 4:43:22 - loss: 4.7768 - accuracy: 0.2420\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_84.npz'\n",
      "none: 58\n",
      "A: 59\n",
      "D 35\n",
      "W 98\n",
      "S 48\n",
      "AW 72\n",
      "AS 47\n",
      "DW 50\n",
      "DS 33\n",
      " 6961/39600 [====>.........................] - ETA: 4:40:22 - loss: 4.7672 - accuracy: 0.2437\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_100.npz'\n",
      "none: 64\n",
      "A: 62\n",
      "D 55\n",
      "W 100\n",
      "S 44\n",
      "AW 67\n",
      "AS 34\n",
      "DW 67\n",
      "DS 7\n",
      " 7461/39600 [====>.........................] - ETA: 4:37:17 - loss: 4.7578 - accuracy: 0.2455\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_54.npz'\n",
      "none: 57\n",
      "A: 40\n",
      "D 26\n",
      "W 98\n",
      "S 37\n",
      "AW 71\n",
      "AS 57\n",
      "DW 54\n",
      "DS 60\n",
      " 7962/39600 [=====>........................] - ETA: 4:33:58 - loss: 4.7482 - accuracy: 0.2473\n",
      "Opening Training File:  b'D:\\\\Data\\\\Data-Course2\\\\training_data2.npz'\n",
      "none: 67\n",
      "A: 53\n",
      "D 35\n",
      "W 89\n",
      "S 59\n",
      "AW 69\n",
      "AS 37\n",
      "DW 61\n",
      "DS 30\n",
      " 8462/39600 [=====>........................] - ETA: 4:30:17 - loss: 4.7390 - accuracy: 0.2490\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_9.npz'\n",
      "none: 25\n",
      "A: 28\n",
      "D 21\n",
      "W 43\n",
      "S 25\n",
      "AW 33\n",
      "AS 24\n",
      "DW 23\n",
      "DS 34\n",
      " 8717/39600 [=====>........................] - ETA: 4:28:28 - loss: 4.7347 - accuracy: 0.2498\n",
      "Opening Training File:  b'D:\\\\Data\\\\John\\\\training_data_5.npz'\n",
      "none: 54\n",
      "A: 61\n",
      "D 63\n",
      "W 77\n",
      "S 54\n",
      "AW 55\n",
      "AS 66\n",
      "DW 60\n",
      "DS 10\n",
      " 9217/39600 [=====>........................] - ETA: 4:25:03 - loss: 4.7268 - accuracy: 0.2511\n",
      "Opening Training File:  b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  FileNotFoundError: [Errno 2] No such file or directory: b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-35-ae1d652ce12c>\", line 14, in tf_data_generator\n    with np.load(fil) as dat:\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\npyio.py\", line 416, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n\nFileNotFoundError: [Errno 2] No such file or directory: b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) Unknown:  FileNotFoundError: [Errno 2] No such file or directory: b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-35-ae1d652ce12c>\", line 14, in tf_data_generator\n    with np.load(fil) as dat:\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\npyio.py\", line 416, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n\nFileNotFoundError: [Errno 2] No such file or directory: b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_9450]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-24f21bf9b145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mclass_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m63\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m37\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m62\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m68\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m62\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     model.fit(train_dataset, validation_data = validation_dataset, class_weight=class_weights, steps_per_epoch = steps_per_epoch,\n\u001b[0m\u001b[0;32m     44\u001b[0m              validation_steps = validation_steps, epochs = epochs, callbacks=[model_checkpoint_callback])\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  FileNotFoundError: [Errno 2] No such file or directory: b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-35-ae1d652ce12c>\", line 14, in tf_data_generator\n    with np.load(fil) as dat:\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\npyio.py\", line 416, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n\nFileNotFoundError: [Errno 2] No such file or directory: b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) Unknown:  FileNotFoundError: [Errno 2] No such file or directory: b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-35-ae1d652ce12c>\", line 14, in tf_data_generator\n    with np.load(fil) as dat:\n\n  File \"C:\\Users\\mille7em\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\npyio.py\", line 416, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n\nFileNotFoundError: [Errno 2] No such file or directory: b'D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0(1).npz'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_9450]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "#Generator version of training function\n",
    "\n",
    "training = True\n",
    "epochs = 5 # 1 epoch is roughly once through each file\n",
    "batch_size = 1\n",
    "num_cases = 50 # estimated number of instances of the least common button press in an average file\n",
    "\n",
    "if training:\n",
    "    file_names = glob.glob(\"D:\\\\Data\\\\**\\*.npz\", recursive=True)\n",
    "    np.random.shuffle(file_names)\n",
    "    # Roughly 80:20 training to validation data split\n",
    "    train_file_names = file_names[0:int(len(file_names)*0.8)]\n",
    "    validation_file_names = file_names[int(len(file_names)*0.8):]\n",
    "\n",
    "    print(\"number of training files = \", len(train_file_names), \"\\nnumber of validation files = \", len(validation_file_names))\n",
    "    \n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_generator(tf_data_generator, args = [train_file_names, batch_size], \n",
    "                                                  output_shapes = (((None,5,416,416,3), (None,5,416,416,3)),(None,9)),\n",
    "                                                  output_types = ((tf.float32, tf.float32), tf.float32))\n",
    "\n",
    "    validation_dataset = tf.data.Dataset.from_generator(tf_data_generator, args = [validation_file_names, batch_size],\n",
    "                                                  output_shapes = (((None,5,416,416,3), (None,5,416,416,3)),(None,9)),\n",
    "                                                  output_types = ((tf.float32, tf.float32), tf.float32))\n",
    "\n",
    "\n",
    "    steps_per_epoch = len(train_file_names)*num_cases*9//batch_size\n",
    "    validation_steps = len(validation_file_names)*num_cases*9//batch_size\n",
    "    print(\"steps_per_epoch = \", steps_per_epoch)\n",
    "    print(\"validation_steps = \", validation_steps)\n",
    "    \n",
    "    # Saves the model at the point in the training where the highest validation accuracy was achieved\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='Model\\\\'+selected_model+\"_checkpoint.h5\",\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    if not Totalling:\n",
    "        class_weights = {0:1, 1:1, 2:1, 3:1, 4:1, 5:1, 6:1, 7:1, 8:1}\n",
    "        #class_weights = {0: 2.151405912040375, 1: 2.1820475847152125, 2: 1.4978370583994232, 3: 3.39689978370584, 4: 1.7534246575342465, 5: 2.476207642393655, 6: 1.834534967555876, 7: 2.1074260994953136, 8: 1.0}\n",
    "\n",
    "    model.fit(train_dataset, validation_data = validation_dataset, class_weight=class_weights, steps_per_epoch = steps_per_epoch,\n",
    "             validation_steps = validation_steps, epochs = epochs, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the learned network (Not reccomended if using callbacks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5py\n",
    "\n",
    "saving = False\n",
    "\n",
    "if saving:\n",
    "    model.save('Model\\\\'+selected_model+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run our model in the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model we want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5py\n",
    "\n",
    "loading = True\n",
    "\n",
    "if loading:\n",
    "    model = load_model('Model\\\\Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plots images from the data file after object detection and separation, then executes and prints a prediction on the sequence\n",
    "Change the filepath and index 'i' if necessary\n",
    "'''\n",
    "\n",
    "plotImgs = True\n",
    "\n",
    "if plotImgs:\n",
    "    print(selected_model)\n",
    "    \n",
    "    with np.load('D:\\\\Data\\\\Miller_Data(1)3-11-2021\\\\training_data0.npz') as data:\n",
    "        training_data = data['data']\n",
    "    \n",
    "    i= 3\n",
    "    \n",
    "    train_objects = []\n",
    "    train_background = []\n",
    "    for j in range(5):\n",
    "        temp1,temp2 = get_sub_images(training_data[i][j])\n",
    "        train_objects.append(temp1)\n",
    "        train_background.append(temp2)\n",
    "    \n",
    "    for j in range(5):\n",
    "        plt.imshow(cv2.cvtColor(train_objects[j], cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        plt.imshow(cv2.cvtColor(train_background[j], cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        print('---------------------------------------------------------')\n",
    "    \n",
    "    X_test = [reshape_custom_X(np.array([train_objects]), verbose=0), reshape_custom_X(np.array([train_background]), verbose=0)]\n",
    "\n",
    "    print (np.argmax(model.predict((X_test[0], X_test[1])), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to test our model in the game, we will reduce the amount of VRAM tensorflow can use so that the game has some VRAM in spare. We will also import the library needed to send inputs to the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the game have some VRAM (needed or the game will crash)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "# For controlling the game\n",
    "from inputsHandler import select_key\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_press(key):\n",
    "    if key == 1:\n",
    "        return'A'\n",
    "    if key == 2:\n",
    "        return'D'\n",
    "    if key == 3:\n",
    "        return'W'\n",
    "    if key == 4:\n",
    "        return'S'\n",
    "    if key == 5:\n",
    "        return'AW'\n",
    "    if key == 6:\n",
    "        return'AS'\n",
    "    if key == 7:\n",
    "        return'DW'\n",
    "    if key == 8:\n",
    "        return'DS'\n",
    "    return 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fuction calculates the Mean Squared Error between 2 images. Is used to detect if the car is stuck somewhere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the run function for our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Configurations\n",
    "show_current_control = False #It will show a windows with a message indicating if the car is currently be controlled by\n",
    "                            #Network  or by a Human\n",
    "    \n",
    "show_whatAIsees = False #It will show the 5 images that the netowrk uses the predict the output \n",
    "\n",
    "enable_evasion = True #If the program detects that the car is not moving (for example because it is stuck facing a wall and\n",
    "                        #the network is not able to return to the road) It will make the car move backwards for a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_IA():\n",
    "    global fps\n",
    "    global front_buffer\n",
    "    global back_buffer\n",
    "    global seq\n",
    "    global key_out\n",
    "    global num\n",
    "    \n",
    "    training_data = []\n",
    "    threads = list()\n",
    "    th_img = threading.Thread(target=img_thread)\n",
    "    th_seq = threading.Thread(target=image_sequencer_thread)\n",
    "    threads.append(th_img)\n",
    "    threads.append(th_seq)\n",
    "    th_img.start()\n",
    "    time.sleep(1)\n",
    "    th_seq.start()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    last_num = 0\n",
    "    \n",
    "    last_time = time.time()\n",
    "    \n",
    "    if show_current_control:\n",
    "        root = Tk()\n",
    "        var = StringVar()\n",
    "        var.set('AI CONTROL')\n",
    "        l = Label(root, textvariable = var, fg='green', font=(\"Courier\", 44))\n",
    "        l.pack()\n",
    "\n",
    "    \n",
    "    while True:\n",
    "       \n",
    "        img_seq = seq.copy()\n",
    "        while len(img_seq) != 5 or last_num==num:\n",
    "            del img_seq\n",
    "            img_seq = seq.copy()\n",
    "        last_num = num\n",
    "        array = [img_seq[0],img_seq[1],img_seq[2],img_seq[3],img_seq[4]]\n",
    "        \n",
    "        objects = []\n",
    "        background = []\n",
    "        for j in range(5):\n",
    "            temp1,temp2 = get_sub_images(array[j])\n",
    "            objects.append(temp1)\n",
    "            background.append(temp2)\n",
    "        \n",
    "        \n",
    "        objects = np.expand_dims(np.array(objects), axis=0)\n",
    "        background = np.expand_dims(np.array(background), axis=0)\n",
    "        p = np.argmax(model.predict([objects,background]))\n",
    "        \n",
    "        if not 'J' in key_check():\n",
    "            select_key(p)\n",
    "            if show_current_control:\n",
    "                var.set('AI CONTROL')\n",
    "                l.config(fg='green')\n",
    "                root.update()\n",
    "        else:\n",
    "            if show_current_control:\n",
    "                var.set('MANUAL CONTROL')\n",
    "                l.config(fg='red')\n",
    "                root.update()\n",
    "\n",
    "        #This is used to detect if the car is stuck somewhere (for example facing a wall) and the network does not know what to do. It will move the car\n",
    "        #backward for a second.\n",
    "        \n",
    "        if enable_evasion:\n",
    "            score = mse(img_seq[0],img_seq[4])\n",
    "            if score < 1000:\n",
    "                if show_current_control:\n",
    "                    var.set('EXECUTING EVASION')\n",
    "                    l.config(fg='blue')\n",
    "                    root.update()\n",
    "                select_key(4)\n",
    "                time.sleep(1)\n",
    "                if np.random.rand()>0.5:\n",
    "                    select_key(6)\n",
    "                else:\n",
    "                    select_key(8)\n",
    "                time.sleep(0.2)\n",
    "                if show_current_control:\n",
    "                    var.set('AI CONTROL')\n",
    "                    l.config(fg='green')\n",
    "                    root.update()\n",
    "\n",
    "        time_act = time.time()\n",
    "        clear_output(wait=True)\n",
    "        stdout.write('Recording at {} FPS \\n'.format(fps))\n",
    "        stdout.write('Images in sequence {} \\n'.format(len(img_seq)))\n",
    "        stdout.write('Actions per second: ' + str(1/(time_act-last_time)) + '\\n')\n",
    "        if enable_evasion:\n",
    "            stdout.write('Diference from img 1 to img 5: ' + str(score))\n",
    "        stdout.flush()\n",
    "        last_time = time.time()\n",
    "        \n",
    "        if show_whatAIsees:\n",
    "            cv2.imshow('window1',np.array(img_seq[0])) \n",
    "            cv2.imshow('window2',np.array(img_seq[1]))\n",
    "            cv2.imshow('window3',np.array(img_seq[2]))\n",
    "            cv2.imshow('window4',np.array(img_seq[3]))\n",
    "            cv2.imshow('window5',np.array(img_seq[4]))\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we run the network in the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_IA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GTA_V-Kernel-GPU",
   "language": "python",
   "name": "gta_v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
